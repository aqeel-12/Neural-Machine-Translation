{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OdoaiW7Nqyja"
      },
      "source": [
        "#Character Level Seq2Seq"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Import all necessary libraries"
      ],
      "metadata": {
        "id": "uciYGwqLm5BF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "fyXH3Ynjdz_O"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from keras.layers import Embedding\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "from google.colab import drive\n",
        "from nltk.translate.bleu_score import corpus_bleu\n",
        "import re\n",
        "import nltk\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-uiuDQ15bJL",
        "outputId": "f71219a8-b000-4177-f73d-a7469db40cfb"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function to convert all sentences into lower case"
      ],
      "metadata": {
        "id": "nxLtDAl6m-FM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def conv_lower_case(input_texts):\n",
        "  lower_case=[]\n",
        "  for sentence in input_texts:\n",
        "    lower_case.append(sentence.lower())\n",
        "  return lower_case"
      ],
      "metadata": {
        "id": "nFMa96Q3gVba"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function to remove quotes"
      ],
      "metadata": {
        "id": "8wR-28EPnDrW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_quotes(input_texts):\n",
        "  remove_quotes=[]\n",
        "  for sentence in input_texts:\n",
        "    remove_quotes.append(re.sub(\"'\",\"\",sentence))\n",
        "  return remove_quotes"
      ],
      "metadata": {
        "id": "qkwvMYFxmfT6"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Merge all datasets "
      ],
      "metadata": {
        "id": "A9dwHySSnm9n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "data_path = \"/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/urd.txt\"\n",
        "num_samples=10000\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "#     # We use \"tab\" as the \"start sequence\" character\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "print(\"##################################################################\")\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/dev.ur', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_urdu = f.read().split(\"\\n\")\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/dev.en', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_eng = f.read().split(\"\\n\")\n",
        "\n",
        "for each in lines_urdu:\n",
        "   target_texts.append(each)\n",
        "\n",
        "for each in lines_eng:\n",
        "  input_texts.append(each)\n",
        "#########################Bible Data############################################\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/train.ur', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_urdu = f.read().split(\"\\n\")\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/train.en', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_eng = f.read().split(\"\\n\")\n",
        "    # print(lines_eng)\n",
        "for each in lines_urdu:\n",
        "   target_texts.append(each)\n",
        "\n",
        "for each in lines_eng:\n",
        "  input_texts.append(each)\n",
        "\n",
        "################Quran Data##########################\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Quran/train.ur', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_urdu = f.read().split(\"\\n\")\n",
        "    # print(len(lines))\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Quran/train.en', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_eng = f.read().split(\"\\n\")\n",
        "for each in lines_urdu:\n",
        "   target_texts.append(each)\n",
        "\n",
        "for each in lines_eng:\n",
        "  input_texts.append(each)\n",
        "\n",
        "###########################Quran Data#########################################\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Quran/dev.ur', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_urdu = f.read().split(\"\\n\")\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Quran/dev.en', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_eng = f.read().split(\"\\n\")\n",
        "\n",
        "for each in lines_urdu:\n",
        "   target_texts.append(each)\n",
        "\n",
        "for each in lines_eng:\n",
        "  input_texts.append(each)\n",
        "\n",
        "#####################################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uM-qdm9Ywaa_",
        "outputId": "1434fdd9-708c-4e29-b0de-d24a620931b4"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_texts=conv_lower_case(input_texts)\n",
        "input_texts=remove_quotes(input_texts)\n",
        "target_texts=remove_quotes(target_texts)"
      ],
      "metadata": {
        "id": "4eOxqnOM0YWP"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Maintain character sets for both source and target data "
      ],
      "metadata": {
        "id": "ABDv20f8qN9W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "id": "fRbLo5C2yeyJ"
      },
      "outputs": [],
      "source": [
        "def inp_out_characters(source_sentences,target_sentences):\n",
        "  input_characters = set()\n",
        "  target_characters = set()\n",
        "  target_texts_updated=[]\n",
        "  for each in input_texts:\n",
        "    for char in each:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "  for each in target_texts:\n",
        "    val= \"\\n\" + each + \"\\t\"\n",
        "    target_texts_updated.append(val)\n",
        "    for char in val:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "  input_characters = sorted(list(input_characters))\n",
        "  target_characters = sorted(list(target_characters))\n",
        "  return input_characters,target_characters,target_texts_updated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "dldrMsdQ4dMj"
      },
      "outputs": [],
      "source": [
        "def data_stats(input_characters,target_characters,source_sentences,target_sentences): \n",
        "  num_encoder_tokens = len(input_characters) \n",
        "  num_decoder_tokens = len(target_characters)\n",
        "  max_encoder_seq_length = max([len(txt) for txt in source_sentences])\n",
        "  max_decoder_seq_length = max([len(txt) for txt in target_sentences])\n",
        "  return num_encoder_tokens,num_decoder_tokens,max_encoder_seq_length,max_decoder_seq_length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "pFhrFnEf4fcu"
      },
      "outputs": [],
      "source": [
        "input_characters,target_characters,target_texts=inp_out_characters(input_texts,target_texts)\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AINoxr1k7Oux",
        "outputId": "cac66a7d-db89-4f30-a2e7-931aaa11f5af"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 15061\n",
            "Number of unique input tokens: 53\n",
            "Number of unique output tokens: 98\n",
            "Max sequence length for inputs: 1203\n",
            "Max sequence length for outputs: 986\n"
          ]
        }
      ],
      "source": [
        "num_encoder_tokens,num_decoder_tokens,max_encoder_seq_length,max_decoder_seq_length=data_stats(input_characters,target_characters,input_texts,target_texts)\n",
        "print(\"Number of samples:\", len(input_texts))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Split into Training & Validation"
      ],
      "metadata": {
        "id": "QXYoLePCqZi2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "Tug5J2RO7RnH"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(input_texts, target_texts, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##To avoid memory crash issues a generaor function is created for encoding for source and target characters"
      ],
      "metadata": {
        "id": "8dnI5DBcqiBu"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "93mH5mCrEsYA"
      },
      "outputs": [],
      "source": [
        "def generate_batch(X = X_train, y = y_train, batch_size = 128):\n",
        "    ''' Generate a batch of data '''\n",
        "    while True:\n",
        "        for j in range(0, len(X), batch_size):\n",
        "            encoder_input_data = np.zeros((batch_size, max_encoder_seq_length),dtype='float32')\n",
        "            decoder_input_data = np.zeros((batch_size, max_encoder_seq_length),dtype='float32')\n",
        "            decoder_target_data = np.zeros((batch_size, max_encoder_seq_length, num_decoder_tokens),dtype='float32')\n",
        "            for i, (input_text, target_text) in enumerate(zip(X[j:j+batch_size], y[j:j+batch_size])):\n",
        "                for t, word in enumerate(input_text):\n",
        "                    #print(\"Input Words\",word)\n",
        "                    encoder_input_data[i, t] = input_token_index[word] # encoder input seq\n",
        "                for t, word in enumerate(target_text):\n",
        "                    #print(\"Target words\",word)\n",
        "                    if t<len(target_text)-1:\n",
        "                        decoder_input_data[i, t] = target_token_index[word] # decoder input seq\n",
        "                    if t>0:\n",
        "                        # decoder target sequence (one hot encoded)\n",
        "                        # does not include the START_ token\n",
        "                        # Offset by one timestep\n",
        "                        decoder_target_data[i, t - 1, target_token_index[word]] = 1.\n",
        "            yield([encoder_input_data, decoder_input_data], decoder_target_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encoder Architecture"
      ],
      "metadata": {
        "id": "Wi5axMs8rH-i"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "e5ShmDqmG0qD"
      },
      "outputs": [],
      "source": [
        "# Encoder\n",
        "latent_dim = 256\n",
        "encoder_inputs = keras.Input(shape=(None,))\n",
        "enc_emb =  Embedding(num_encoder_tokens, latent_dim, mask_zero = True)(encoder_inputs)\n",
        "encoder_lstm = keras.layers.LSTM(latent_dim, return_state=True)\n",
        "encoder_outputs, state_h, state_c = encoder_lstm(enc_emb)\n",
        "# We discard `encoder_outputs` and only keep the states.\n",
        "encoder_states = [state_h, state_c]"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encoder states supplied as decoder initial state"
      ],
      "metadata": {
        "id": "3ArvKwf7rN_m"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "v-LpGZnuG2uL"
      },
      "outputs": [],
      "source": [
        "# Set up the decoder, using `encoder_states` as initial state.\n",
        "decoder_inputs = keras.Input(shape=(None,))\n",
        "dec_emb_layer = Embedding(num_decoder_tokens, latent_dim, mask_zero = True)\n",
        "dec_emb = dec_emb_layer(decoder_inputs)\n",
        "# We set up our decoder to return full output sequences,\n",
        "# and to return internal states as well. We don't use the\n",
        "# return states in the training model, but we will use them in inference.\n",
        "decoder_lstm = keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)\n",
        "decoder_outputs, _, _ = decoder_lstm(dec_emb,\n",
        "                                     initial_state=encoder_states)\n",
        "decoder_dense = keras.layers.Dense(num_decoder_tokens, activation='softmax')\n",
        "decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "# Define the model that will turn\n",
        "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
        "model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yio3K4acAx1p"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HHPqdmKxA08R",
        "outputId": "05c52c21-9671-4035-83d8-437026185cb7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " input_2 (InputLayer)           [(None, None)]       0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, None, 256)    13568       ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " embedding_1 (Embedding)        (None, None, 256)    25088       ['input_2[0][0]']                \n",
            "                                                                                                  \n",
            " lstm (LSTM)                    [(None, 256),        525312      ['embedding[0][0]']              \n",
            "                                 (None, 256),                                                     \n",
            "                                 (None, 256)]                                                     \n",
            "                                                                                                  \n",
            " lstm_1 (LSTM)                  [(None, None, 256),  525312      ['embedding_1[0][0]',            \n",
            "                                 (None, 256),                     'lstm[0][1]',                   \n",
            "                                 (None, 256)]                     'lstm[0][2]']                   \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, None, 98)     25186       ['lstm_1[0][0]']                 \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 1,114,466\n",
            "Trainable params: 1,114,466\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCMUKRYhG6Ag"
      },
      "outputs": [],
      "source": [
        "train_samples = len(X_train)\n",
        "val_samples = len(X_test)\n",
        "batch_size = 128\n",
        "epochs = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generator function for model fitting to fetch one record at a time to avoid memory crash issues"
      ],
      "metadata": {
        "id": "twGFWl0vrYr1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n",
        "                    steps_per_epoch = train_samples//batch_size,\n",
        "                    epochs=epochs, \n",
        "                    validation_data = generate_batch(X_test, y_test, batch_size = batch_size),\n",
        "                    validation_steps = val_samples//batch_size)"
      ],
      "metadata": {
        "id": "3PpA5Y8KjZAM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd10b93-02a2-4184-b8b6-0fe3d617ffba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-18-60427f4dd8dc>:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(generator = generate_batch(X_train, y_train, batch_size = batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "105/105 [==============================] - 350s 3s/step - loss: 0.2745 - accuracy: 0.2919 - val_loss: 0.2345 - val_accuracy: 0.3566\n",
            "Epoch 2/30\n",
            "105/105 [==============================] - 324s 3s/step - loss: 0.2246 - accuracy: 0.3829 - val_loss: 0.2109 - val_accuracy: 0.4128\n",
            "Epoch 3/30\n",
            "105/105 [==============================] - 327s 3s/step - loss: 0.2049 - accuracy: 0.4318 - val_loss: 0.1942 - val_accuracy: 0.4560\n",
            "Epoch 4/30\n",
            "105/105 [==============================] - 327s 3s/step - loss: 0.1896 - accuracy: 0.4701 - val_loss: 0.1820 - val_accuracy: 0.4838\n",
            "Epoch 5/30\n",
            "105/105 [==============================] - 330s 3s/step - loss: 0.1778 - accuracy: 0.5000 - val_loss: 0.1717 - val_accuracy: 0.5144\n",
            "Epoch 6/30\n",
            "105/105 [==============================] - 326s 3s/step - loss: 0.1684 - accuracy: 0.5230 - val_loss: 0.1632 - val_accuracy: 0.5329\n",
            "Epoch 7/30\n",
            "105/105 [==============================] - 328s 3s/step - loss: 0.1614 - accuracy: 0.5411 - val_loss: 0.1573 - val_accuracy: 0.5506\n",
            "Epoch 8/30\n",
            "105/105 [==============================] - 325s 3s/step - loss: 0.1557 - accuracy: 0.5563 - val_loss: 0.1525 - val_accuracy: 0.5619\n",
            "Epoch 9/30\n",
            "105/105 [==============================] - 325s 3s/step - loss: 0.1509 - accuracy: 0.5687 - val_loss: 0.1475 - val_accuracy: 0.5755\n",
            "Epoch 10/30\n",
            "105/105 [==============================] - 324s 3s/step - loss: 0.1471 - accuracy: 0.5787 - val_loss: 0.1442 - val_accuracy: 0.5825\n",
            "Epoch 11/30\n",
            "105/105 [==============================] - 324s 3s/step - loss: 0.1439 - accuracy: 0.5872 - val_loss: 0.1417 - val_accuracy: 0.5899\n",
            "Epoch 12/30\n",
            "105/105 [==============================] - 327s 3s/step - loss: 0.1412 - accuracy: 0.5943 - val_loss: 0.1399 - val_accuracy: 0.5936\n",
            "Epoch 13/30\n",
            "105/105 [==============================] - 324s 3s/step - loss: 0.1387 - accuracy: 0.6003 - val_loss: 0.1377 - val_accuracy: 0.5997\n",
            "Epoch 14/30\n",
            "105/105 [==============================] - 320s 3s/step - loss: 0.1366 - accuracy: 0.6055 - val_loss: 0.1353 - val_accuracy: 0.6070\n",
            "Epoch 15/30\n",
            "105/105 [==============================] - 325s 3s/step - loss: 0.1348 - accuracy: 0.6100 - val_loss: 0.1341 - val_accuracy: 0.6092\n",
            "Epoch 16/30\n",
            "105/105 [==============================] - 328s 3s/step - loss: 0.1329 - accuracy: 0.6144 - val_loss: 0.1324 - val_accuracy: 0.6140\n",
            "Epoch 17/30\n",
            "105/105 [==============================] - 326s 3s/step - loss: 0.1316 - accuracy: 0.6181 - val_loss: 0.1313 - val_accuracy: 0.6173\n",
            "Epoch 18/30\n",
            "105/105 [==============================] - 322s 3s/step - loss: 0.1302 - accuracy: 0.6221 - val_loss: 0.1302 - val_accuracy: 0.6181\n",
            "Epoch 19/30\n",
            "105/105 [==============================] - 327s 3s/step - loss: 0.1289 - accuracy: 0.6250 - val_loss: 0.1300 - val_accuracy: 0.6198\n",
            "Epoch 20/30\n",
            "105/105 [==============================] - 325s 3s/step - loss: 0.1276 - accuracy: 0.6281 - val_loss: 0.1292 - val_accuracy: 0.6201\n",
            "Epoch 21/30\n",
            "105/105 [==============================] - 322s 3s/step - loss: 0.1264 - accuracy: 0.6308 - val_loss: 0.1278 - val_accuracy: 0.6252\n",
            "Epoch 22/30\n",
            "105/105 [==============================] - 319s 3s/step - loss: 0.1255 - accuracy: 0.6332 - val_loss: 0.1262 - val_accuracy: 0.6296\n",
            "Epoch 23/30\n",
            "105/105 [==============================] - 323s 3s/step - loss: 0.1246 - accuracy: 0.6356 - val_loss: 0.1259 - val_accuracy: 0.6311\n",
            "Epoch 24/30\n",
            "105/105 [==============================] - 320s 3s/step - loss: 0.1237 - accuracy: 0.6381 - val_loss: 0.1254 - val_accuracy: 0.6318\n",
            "Epoch 25/30\n",
            "105/105 [==============================] - 321s 3s/step - loss: 0.1229 - accuracy: 0.6403 - val_loss: 0.1246 - val_accuracy: 0.6344\n",
            "Epoch 26/30\n",
            "105/105 [==============================] - 324s 3s/step - loss: 0.1221 - accuracy: 0.6424 - val_loss: 0.1242 - val_accuracy: 0.6348\n",
            "Epoch 27/30\n",
            "105/105 [==============================] - 321s 3s/step - loss: 0.1212 - accuracy: 0.6445 - val_loss: 0.1241 - val_accuracy: 0.6349\n",
            "Epoch 28/30\n",
            "105/105 [==============================] - 321s 3s/step - loss: 0.1204 - accuracy: 0.6465 - val_loss: 0.1231 - val_accuracy: 0.6387\n",
            "Epoch 29/30\n",
            "105/105 [==============================] - 323s 3s/step - loss: 0.1197 - accuracy: 0.6483 - val_loss: 0.1226 - val_accuracy: 0.6386\n",
            "Epoch 30/30\n",
            "105/105 [==============================] - 324s 3s/step - loss: 0.1191 - accuracy: 0.6499 - val_loss: 0.1219 - val_accuracy: 0.6417\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f2ab020c520>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_weights('/content/drive/MyDrive/Colab Notebooks/NLP_Project/char_level_model.h5')"
      ],
      "metadata": {
        "id": "haFEDItvKP3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_weights('/content/drive/MyDrive/Colab Notebooks/NLP_Project/char_level_model.h5')"
      ],
      "metadata": {
        "id": "62vvc8vGK9p-"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decoder architecture"
      ],
      "metadata": {
        "id": "FZ8AgHwyrlR-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "id": "wY0yaH8hG9fF"
      },
      "outputs": [],
      "source": [
        "encoder_model = keras.Model(encoder_inputs, encoder_states)\n",
        "\n",
        "#decoder_inputs = model.input[1]  # input_2\n",
        "decoder_state_input_h = keras.Input(shape=(latent_dim,))\n",
        "decoder_state_input_c = keras.Input(shape=(latent_dim,))\n",
        "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
        "dec_emb2=dec_emb_layer(decoder_inputs)\n",
        "#decoder_lstm = model.layers[3]\n",
        "\n",
        "decoder_outputs2, state_h_dec, state_c_dec = decoder_lstm(dec_emb2, initial_state=decoder_states_inputs)\n",
        "decoder_states2 = [state_h_dec, state_c_dec]\n",
        "#decoder_dense = model.layers[4]\n",
        "decoder_outputs2 = decoder_dense(decoder_outputs2)\n",
        "\n",
        "decoder_model = keras.Model(\n",
        "    [decoder_inputs] + decoder_states_inputs, [decoder_outputs2] + decoder_states2\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "id": "CtSH9rdSJ-dE"
      },
      "outputs": [],
      "source": [
        "# Reverse-lookup token index to decode sequences back to\n",
        "# something readable.\n",
        "reverse_input_char_index = dict((i, char) for char, i in input_token_index.items())\n",
        "reverse_target_char_index = dict((i, char) for char, i in target_token_index.items())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Function to decode/translate the input seq"
      ],
      "metadata": {
        "id": "hS9cE8KXrp2L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "2kEJl5vGKAS7"
      },
      "outputs": [],
      "source": [
        "def decode_sequence(input_seq):\n",
        "    # Encode the input as state vectors.\n",
        "    states_value = encoder_model.predict(input_seq,verbose=0)\n",
        "    #print(\"state value predictions: \",states_value)\n",
        "    # Generate empty target sequence of length 1.\n",
        "    target_seq = np.zeros((1, 1))\n",
        "    # Populate the first character of target sequence with the start character.\n",
        "    target_seq[0, 0]= target_token_index['\\t']\n",
        "\n",
        "    # Sampling loop for a batch of sequences\n",
        "    # (to simplify, here we assume a batch of size 1).\n",
        "    stop_condition = False\n",
        "    decoded_sentence = \"\"\n",
        "    while not stop_condition:\n",
        "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value,verbose=0)\n",
        "\n",
        "        # Sample a token\n",
        "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
        "        decoded_sentence += sampled_char\n",
        "\n",
        "        # Exit condition: either hit max length\n",
        "        # or find stop character.\n",
        "        if sampled_char == \"\\n\" or len(decoded_sentence) > 100:\n",
        "            stop_condition = True\n",
        "            #print(\"Inside break cond\")\n",
        "\n",
        "        # Update the target sequence (of length 1).\n",
        "        target_seq = np.zeros((1, 1))\n",
        "        target_seq[0, 0] =sampled_token_index\n",
        "\n",
        "        # Update states\n",
        "        states_value = [h, c]\n",
        "    return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "iF85SMGZKCXk"
      },
      "outputs": [],
      "source": [
        "train_gen=generate_batch(X_train,y_train,batch_size=1)\n",
        "k=-1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "pp2ZwvFqKEqC",
        "outputId": "93e434ca-58c1-4ef0-ab34-34d43851e560"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'abraham saith unto him , they have moses and the prophets ; let them hear them .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Buf1mJ1eKGiH",
        "outputId": "e60836a7-f61b-4a3d-fb87-8a95c596a3ca"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nابرہام نے اس سے کہا ان کے پاس موسٰی اور انبیا تو ہیں ۔ ان کی سنیں ۔\\t'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "y_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "beA3ei0uKIK6",
        "outputId": "6114d00a-08e0-413d-d146-33892bba78a5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "[[25. 26. 42. ...  0.  0.  0.]]\n",
            "(1203,)\n",
            "Input Source sentence: ['abraham saith unto him , they have moses and the prophets ; let them hear them .']\n",
            "Actual Target Translation: ['\\nابرہام نے اس سے کہا ان کے پاس موسٰی اور انبیا تو ہیں ۔ ان کی سنیں ۔\\t']\n",
            "Predicted Target Translation: جھے کہ اس کے ساتھ اس کے ساتھ ایسا ہؤا کہ اس کے ساتھ اس کی بات کی بات کی بات کرتے ہو ۔\tجار ۔\tجھ نہ کر\n"
          ]
        }
      ],
      "source": [
        "k+=1\n",
        "print(k)\n",
        "(input_seq,actual_output),_=next(train_gen)\n",
        "print(input_seq)\n",
        "decoded_sentence=decode_sequence(input_seq)\n",
        "print(input_seq[0].shape)\n",
        "print('Input Source sentence:', X_train[k:k+1])\n",
        "print('Actual Target Translation:', y_train[k:k+1])\n",
        "print('Predicted Target Translation:', decoded_sentence)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing"
      ],
      "metadata": {
        "id": "tmJ6JXmnrwEO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjPrT1jbKLk4"
      },
      "outputs": [],
      "source": [
        "def anything_goes_translation(src_sentence,max_encoder_seq_length):\n",
        "  encoder_input_data = np.zeros((1, max_encoder_seq_length), dtype='float32')\n",
        "  for i,input_text in enumerate(src_sentence):\n",
        "    for t, word in enumerate(input_text):\n",
        "      encoder_input_data[i, t] = input_token_index[word] # encoder input seg\n",
        "  decoded_sentence=decode_sequence(encoder_input_data)\n",
        "  return decoded_sentence"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def test_data():\n",
        "  test_source = []\n",
        "  test_target = []\n",
        "  with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/test.ur', \"r\", encoding=\"utf-8\") as f:\n",
        "      lines_urdu = f.read().split(\"\\n\")\n",
        "  with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/test.en', \"r\", encoding=\"utf-8\") as f:\n",
        "      lines_eng = f.read().split(\"\\n\")\n",
        "  for each in lines_eng:\n",
        "    test_source.append(each)\n",
        "  for each in lines_urdu:\n",
        "    test_target.append(each)\n",
        "  return test_source,test_target\n",
        "test_source,test_target=test_data()  "
      ],
      "metadata": {
        "id": "GqMJ6Ip4OVEJ"
      },
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_source=conv_lower_case(test_source)\n",
        "test_source=remove_quotes(test_source)\n",
        "test_target=remove_quotes(test_target)"
      ],
      "metadata": {
        "id": "LwlxKlMjVhY3"
      },
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def inp_out_characters(source_sentences,target_sentences):\n",
        "  input_characters = set()\n",
        "  target_characters = set()\n",
        "  target_texts_updated=[]\n",
        "  for each in source_sentences:\n",
        "    for char in each:\n",
        "        if char not in input_characters:\n",
        "            input_characters.add(char)\n",
        "  for each in target_sentences:\n",
        "    val= \"\\n\" + each + \"\\t\"\n",
        "    target_texts_updated.append(val)\n",
        "    for char in val:\n",
        "        if char not in target_characters:\n",
        "            target_characters.add(char)\n",
        "  input_characters = sorted(list(input_characters))\n",
        "  target_characters = sorted(list(target_characters))\n",
        "  return input_characters,target_characters,target_texts_updated"
      ],
      "metadata": {
        "id": "dgDygQbfdgD2"
      },
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_stats(input_characters,target_characters,source_sentences,target_sentences): \n",
        "  num_encoder_tokens = len(input_characters) \n",
        "  num_decoder_tokens = len(target_characters)\n",
        "  max_encoder_seq_length = max([len(txt) for txt in source_sentences])\n",
        "  max_decoder_seq_length = max([len(txt) for txt in target_sentences])\n",
        "  return num_encoder_tokens,num_decoder_tokens,max_encoder_seq_length,max_decoder_seq_length"
      ],
      "metadata": {
        "id": "Sih_uyjidoBq"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_characters,target_characters,test_target=inp_out_characters(test_source,test_target)\n",
        "input_token_index = dict([(char, i) for i, char in enumerate(input_characters)])\n",
        "target_token_index = dict([(char, i) for i, char in enumerate(target_characters)])"
      ],
      "metadata": {
        "id": "KyKzA4PxdrQY"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_encoder_tokens,num_decoder_tokens,max_encoder_seq_length,max_decoder_seq_length=data_stats(input_characters,target_characters,test_source,test_target)\n",
        "print(\"Number of samples:\", len(test_source))\n",
        "print(\"Number of unique input tokens:\", num_encoder_tokens)\n",
        "print(\"Number of unique output tokens:\", num_decoder_tokens)\n",
        "print(\"Max sequence length for inputs:\", max_encoder_seq_length)\n",
        "print(\"Max sequence length for outputs:\", max_decoder_seq_length)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A38uCvIYdvmx",
        "outputId": "93fada98-662d-4b52-8d0c-8609498b02b1"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples: 258\n",
            "Number of unique input tokens: 33\n",
            "Number of unique output tokens: 50\n",
            "Max sequence length for inputs: 371\n",
            "Max sequence length for outputs: 335\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BLEU Score"
      ],
      "metadata": {
        "id": "DDWA1L9b3Vur"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = [] \n",
        "total = 0\n",
        "for i in range(len(test_source)):\n",
        "  result.append(anything_goes_translation([test_source[i]],max_encoder_seq_length))\n",
        "  total += nltk.translate.bleu_score.sentence_bleu([test_target[i]], result[-1], weights=[1])\n",
        "print(total/len(test_source))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8p7sHL9I-S6",
        "outputId": "3c1e6a5d-7c8e-46ca-f02d-2df37872d721"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5043227598614135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score=total/len(test_source)\n",
        "print(\"Bleu Score: \",bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASZYjYPWJ84Q",
        "outputId": "fae7ce72-9dcb-4aab-89c0-081fc06e679c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu Score:  0.5043227598614135\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bleu_Score_Char_Level', 'wb') as file:\n",
        "  pickle.dump(bleu_score, file)"
      ],
      "metadata": {
        "id": "paAPWXD5MCnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Neural Machine Translation With Attention\n",
        "\n",
        "**Source:** https://www.tensorflow.org/text/tutorials/nmt_with_attention"
      ],
      "metadata": {
        "id": "dcuLlOOrcgoc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4D3-GI5eick",
        "outputId": "edc73883-8c10-4d3f-a61b-78ed9b99d62e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.6.0-py3-none-any.whl (41 kB)\n",
            "\u001b[K     |████████████████████████████████| 41 kB 138 kB/s \n",
            "\u001b[?25hInstalling collected packages: einops\n",
            "Successfully installed einops-0.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PCaJfxvnetxl",
        "outputId": "2dd728c6-aeeb-47f7-ebe3-66d26fd3ee6d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 5.8 MB 33.6 MB/s \n",
            "\u001b[?25hCollecting tensorflow<2.12,>=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 588.3 MB 18 kB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.15.0)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[K     |████████████████████████████████| 439 kB 64.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.19.6)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-22.12.6-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (4.4.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.51.1)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.21.6)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.7 MB 48.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.28.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.3.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (14.0.6)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (2.1.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (21.3)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.0 MB 24.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.15.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.4.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (4.13.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.2.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.0.9)\n",
            "Installing collected packages: tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-22.12.6 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os \n",
        "import sys \n",
        "import random\n",
        "import time\n",
        "import re\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "from typing import Any, Tuple \n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "import einops \n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.ticker as ticker \n",
        "\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split \n",
        "from sklearn.metrics import precision_score, recall_score, f1_score \n",
        "from sklearn import preprocessing \n",
        "\n",
        "random.seed(16)\n",
        "import tensorflow as tf \n",
        "import tensorflow_text  as tf_text \n",
        "#from Bio import pairwise2\n",
        "from functools import partial\n",
        "from collections import deque\n",
        "import pathlib\n",
        "use_builtins = True\n",
        "import pickle as pkl "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDAM_2-Bcjb6",
        "outputId": "f2101bf8-018b-45e3-89a2-f5707bc87cad"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load and merge all the datasets"
      ],
      "metadata": {
        "id": "WJ6VU4NDIwWi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the data.\n",
        "input_texts = []\n",
        "target_texts = []\n",
        "data_path = \"/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/urd.txt\"\n",
        "num_samples=10000\n",
        "with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    lines = f.read().split(\"\\n\")\n",
        "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
        "    input_text, target_text, _ = line.split(\"\\t\")\n",
        "#     # We use \"tab\" as the \"start sequence\" character\n",
        "    input_texts.append(input_text)\n",
        "    target_texts.append(target_text)\n",
        "print(\"##################################################################\")\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/dev.ur', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_urdu = f.read().split(\"\\n\")\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/dev.en', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_eng = f.read().split(\"\\n\")\n",
        "\n",
        "for each in lines_urdu:\n",
        "   target_texts.append(each)\n",
        "\n",
        "for each in lines_eng:\n",
        "  input_texts.append(each)\n",
        "#########################Bible Data############################################\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/train.ur', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_urdu = f.read().split(\"\\n\")\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/train.en', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_eng = f.read().split(\"\\n\")\n",
        "    # print(lines_eng)\n",
        "for each in lines_urdu:\n",
        "   target_texts.append(each)\n",
        "\n",
        "for each in lines_eng:\n",
        "  input_texts.append(each)\n",
        "\n",
        "################Quran Data##########################\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Quran/train.ur', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_urdu = f.read().split(\"\\n\")\n",
        "    # print(len(lines))\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Quran/train.en', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_eng = f.read().split(\"\\n\")\n",
        "for each in lines_urdu:\n",
        "   target_texts.append(each)\n",
        "\n",
        "for each in lines_eng:\n",
        "  input_texts.append(each)\n",
        "\n",
        "###########################Quran Data#########################################\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Quran/dev.ur', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_urdu = f.read().split(\"\\n\")\n",
        "\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Quran/dev.en', \"r\", encoding=\"utf-8\") as f:\n",
        "    lines_eng = f.read().split(\"\\n\")\n",
        "\n",
        "for each in lines_urdu:\n",
        "   target_texts.append(each)\n",
        "\n",
        "for each in lines_eng:\n",
        "  input_texts.append(each)\n",
        "\n",
        "#####################################################################"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmvDDdaNKZXc",
        "outputId": "dcb471ee-2d92-40c3-ce83-718bead2bf24"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "##################################################################\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "context_raw=input_texts\n",
        "target_raw=target_texts\n",
        "print(len(context_raw))\n",
        "print(len(target_raw))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zVw7P2Mg6Ghf",
        "outputId": "1571c45e-5589-41c0-8b34-5fea1e200860"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "15061\n",
            "15061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ShapeChecker():\n",
        "    def __init__(self):\n",
        "        # Keep a cache of every axis-name seen\n",
        "        self.shapes = {}\n",
        "\n",
        "    def __call__(self, tensor, names, broadcast=False):\n",
        "        if not tf.executing_eagerly():\n",
        "            return\n",
        "\n",
        "        parsed = einops.parse_shape(tensor, names)\n",
        "\n",
        "        for name, new_dim in parsed.items():\n",
        "            old_dim = self.shapes.get(name, None)\n",
        "\n",
        "            if (broadcast and new_dim == 1):\n",
        "                continue\n",
        "\n",
        "            if old_dim is None:\n",
        "                # If the axis name is new, add its length to the cache.\n",
        "                self.shapes[name] = new_dim\n",
        "                continue\n",
        "\n",
        "            if new_dim != old_dim:\n",
        "                raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n",
        "                                 f\"    found: {new_dim}\\n\"\n",
        "                                 f\"    expected: {old_dim}\\n\")"
      ],
      "metadata": {
        "id": "eDvsI22lfrz_"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(context_raw[-2])\n",
        "print(target_raw[-2])\n",
        "print(len(context_raw))\n",
        "print(len(target_raw))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgwdDFhkfzvS",
        "outputId": "2dde7180-9bec-4758-849e-08751a1b63a1"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Or feeding on a day of scarcity ( the poor and the needy during famine and scarcity i . e . striving to put an end to their sufferings and economic deadlock ) .\n",
            "یا بھوک والے دن یعنی قحط و افلاس کے دور میں غریبوں اور محروم المعیشت لوگوں کو کھانا کھلانا ہے یعنی ان کے معاشی تعطل اور ابتلاء کو ختم کرنے کی جد و جہد کرنا ہے ۔\n",
            "15061\n",
            "15061\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.array(context_raw[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eDN9PaMggIqz",
        "outputId": "8efda629-cba5-40e3-ca60-fbbe5b5fcbcc"
      },
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array('Hi.', dtype='<U3')"
            ]
          },
          "metadata": {},
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##From these arrays of strings you can create a tf.data.Dataset of strings that shuffles and batches them efficiently:"
      ],
      "metadata": {
        "id": "O3AwI0ziJAYq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BUFFER_SIZE = len(context_raw)\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n",
        "\n",
        "context_raw_train = []\n",
        "target_raw_train = []  \n",
        "context_raw_val = []\n",
        "target_raw_val = []\n",
        "for i in range(len(is_train)):\n",
        "    if is_train[i]: \n",
        "        context_raw_train.append(context_raw[i])\n",
        "        target_raw_train.append(target_raw[i])\n",
        "    else:\n",
        "        context_raw_val.append(context_raw[i])\n",
        "        target_raw_val.append(target_raw[i])\n",
        "        \n",
        "\n",
        "train_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw_train, target_raw_train))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))\n",
        "\n",
        "val_raw = (\n",
        "    tf.data.Dataset\n",
        "    .from_tensor_slices((context_raw_val, target_raw_val))\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE))"
      ],
      "metadata": {
        "id": "4aj0j71AgPtE"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for example_context_strings, example_target_strings in train_raw.take(1):\n",
        "    print(example_context_strings[:5])\n",
        "    print()\n",
        "    print(example_target_strings[:5])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GvtUEWa6gomn",
        "outputId": "2f9c9986-cba2-4168-fd59-7331c4ad8b0c"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'And I saw when the Lamb opened one of the seals , and I heard , as it were the noise of thunder , one of the four beasts saying , Come and see .'\n",
            " b'God forbid : yea , let God be true , but every man a liar ; as it is written , That thou mightest be justified in thy sayings , and mightest overcome when thou art judged .'\n",
            " b'And ( the disbelievers ) say : The Most Kind ( Lord ) has taken ( to Himself ) a son .'\n",
            " b'You can come at any time.' b'I had a heart attack.'], shape=(5,), dtype=string)\n",
            "\n",
            "tf.Tensor(\n",
            "[b'\\xd9\\xbe\\xda\\xbe\\xd8\\xb1 \\xd9\\x85\\xdb\\x8c\\xda\\xba \\xd9\\x86\\xdb\\x92 \\xd8\\xaf\\xdb\\x8c\\xda\\xa9\\xda\\xbe\\xd8\\xa7 \\xda\\xa9\\xdb\\x81 \\xd8\\xa8\\xd8\\xb1\\xdb\\x81 \\xd9\\x86\\xdb\\x92 \\xd8\\xa7\\xd9\\x86 \\xd8\\xb3\\xd8\\xa7\\xd8\\xaa \\xd9\\x85\\xdb\\x81\\xd8\\xb1\\xd9\\x88\\xda\\xba \\xd9\\x85\\xdb\\x8c\\xda\\xba \\xd8\\xb3\\xdb\\x92 \\xd8\\xa7\\xdb\\x8c\\xda\\xa9 \\xda\\xa9\\xd9\\x88 \\xda\\xa9\\xda\\xbe\\xd9\\x88\\xd9\\x84\\xd8\\xa7 \\xd8\\xa7\\xd9\\x88\\xd8\\xb1 \\xd8\\xa7\\xd9\\x86 \\xda\\x86\\xd8\\xa7\\xd8\\xb1\\xd9\\x88\\xda\\xba \\xd8\\xac\\xd8\\xa7\\xd9\\x86\\xd8\\xaf\\xd8\\xa7\\xd8\\xb1\\xd9\\x88\\xda\\xba \\xd9\\x85\\xdb\\x8c\\xda\\xba \\xd8\\xb3\\xdb\\x92 \\xd8\\xa7\\xdb\\x8c\\xda\\xa9 \\xda\\xa9\\xdb\\x8c \\xda\\xaf\\xd8\\xb1\\xd8\\xac \\xda\\xa9\\xdb\\x8c \\xd8\\xb3\\xdb\\x8c \\xdb\\x8c\\xdb\\x81 \\xd8\\xa2\\xd9\\x88\\xd8\\xa7\\xd8\\xb2 \\xd8\\xb3\\xd9\\x86\\xdb\\x8c \\xda\\xa9\\xdb\\x81 \\xd8\\xa2 \\xdb\\x94'\n",
            " b'\\xdb\\x81\\xd8\\xb1\\xda\\xaf\\xd8\\xb2 \\xd9\\x86\\xdb\\x81\\xdb\\x8c\\xda\\xba \\xdb\\x94 \\xd8\\xa8\\xd9\\x84\\xda\\xa9\\xdb\\x81 \\xd8\\xae\\xd8\\xaf\\xd8\\xa7 \\xd8\\xb3\\xda\\x86\\xd8\\xa7 \\xd9\\xb9\\xda\\xbe\\xdb\\x81\\xd8\\xb1\\xdb\\x92 \\xd8\\xa7\\xd9\\x88\\xd8\\xb1 \\xdb\\x81\\xd8\\xb1 \\xd8\\xa7\\xdb\\x8c\\xda\\xa9 \\xd8\\xa2\\xd8\\xaf\\xd9\\x85\\xdb\\x8c \\xd8\\xac\\xda\\xbe\\xd9\\x88\\xd9\\xb9\\xd8\\xa7 \\xdb\\x94 \\xda\\x86\\xd9\\x86\\xd8\\xa7\\xd9\\x86\\xda\\x86\\xdb\\x81 \\xd9\\x84\\xda\\xa9\\xda\\xbe\\xd8\\xa7 \\xdb\\x81\\xdb\\x92 \\xda\\xa9\\xdb\\x81 \\xd8\\xaa\\xd9\\x88 \\xd8\\xa7\\xd9\\xbe\\xd9\\x86\\xdb\\x8c \\xd8\\xa8\\xd8\\xa7\\xd8\\xaa\\xd9\\x88\\xda\\xba \\xd9\\x85\\xdb\\x8c\\xda\\xba \\xd8\\xb1\\xd8\\xa7\\xd8\\xb3\\xd8\\xaa\\xd8\\xa8\\xd8\\xa7\\xd8\\xb2 \\xd9\\xb9\\xda\\xbe\\xdb\\x81\\xd8\\xb1\\xdb\\x92 \\xd8\\xa7\\xd9\\x88\\xd8\\xb1 \\xd8\\xa7\\xd9\\xbe\\xd9\\x86\\xdb\\x92 \\xd9\\x85\\xd9\\x82\\xd8\\xaf\\xd9\\x85\\xdb\\x81 \\xd9\\x85\\xdb\\x8c\\xda\\xba \\xd9\\x81\\xd8\\xaa\\xd8\\xad \\xd9\\xbe\\xd8\\xa7\\xd8\\xa6\\xdb\\x92 \\xdb\\x94'\n",
            " b'\\xd8\\xa7\\xd9\\x88\\xd8\\xb1 \\xda\\xa9\\xd8\\xa7\\xd9\\x81\\xd8\\xb1 \\xda\\xa9\\xdb\\x81\\xd8\\xaa\\xdb\\x92 \\xdb\\x81\\xdb\\x8c\\xda\\xba \\xda\\xa9\\xdb\\x81 \\xd8\\xae\\xd8\\xaf\\xd8\\xa7\\xd8\\xa6\\xdb\\x92 \\xd8\\xb1\\xd8\\xad\\xd9\\x85\\xd8\\xa7\\xd9\\x86 \\xd9\\x86\\xdb\\x92 \\xd8\\xa7\\xd9\\xbe\\xd9\\x86\\xdb\\x92 \\xd9\\x84\\xd8\\xa6\\xdb\\x92 \\xd9\\x84\\xda\\x91\\xda\\xa9\\xd8\\xa7 \\xd8\\xa8\\xd9\\x86\\xd8\\xa7 \\xd9\\x84\\xdb\\x8c\\xd8\\xa7 \\xdb\\x81\\xdb\\x92 \\xdb\\x94'\n",
            " b'\\xd8\\xa2\\xd9\\xbe \\xda\\xa9\\xd8\\xb3\\xdb\\x8c \\xd9\\x88\\xd9\\x82\\xd8\\xaa \\xd8\\xa8\\xda\\xbe\\xdb\\x8c \\xd8\\xa2 \\xd8\\xb3\\xda\\xa9\\xd8\\xaa\\xdb\\x92 \\xdb\\x81\\xdb\\x92\\xdb\\x94'\n",
            " b'\\xd9\\x85\\xd8\\xac\\xda\\xbe\\xdb\\x92 \\xd8\\xaf\\xd9\\x84 \\xda\\xa9\\xd8\\xa7 \\xd8\\xaf\\xd9\\x88\\xd8\\xb1\\xdb\\x81 \\xd9\\xbe\\xda\\x91\\xd8\\xa7 \\xd8\\xaa\\xda\\xbe\\xd8\\xa7\\xdb\\x94'], shape=(5,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Standardization"
      ],
      "metadata": {
        "id": "wpRn441hLus1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tf.constant('But Jesus yet answered nothing ; so that Pilate marvelled .')\n",
        "print(example_text.numpy())\n",
        "print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHftbY3HhF14",
        "outputId": "e8d8c1a7-3c15-4f69-9c54-4302ea406a13"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'But Jesus yet answered nothing ; so that Pilate marvelled .'\n",
            "b'But Jesus yet answered nothing ; so that Pilate marvelled .'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Unicode normalization"
      ],
      "metadata": {
        "id": "Zp-3WTWxL2AX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tf_lower_and_split_punct(text):\n",
        "    # Split accented characters.\n",
        "    text = tf_text.normalize_utf8(text, 'NFKD')\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.strip(text)\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text"
      ],
      "metadata": {
        "id": "rlKo-WTNhn7M"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct(example_text).numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mlIccfTziWbR",
        "outputId": "ec8e7a67-76fc-4b36-fa5d-dd0f0450fd20"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "But Jesus yet answered nothing ; so that Pilate marvelled .\n",
            "[START] but jesus yet answered nothing ; so that pilate marvelled . [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Vectorization"
      ],
      "metadata": {
        "id": "ASwjk0rbL8s8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_size = 10000\n",
        "context_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)"
      ],
      "metadata": {
        "id": "03SKIcLcieLZ"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "context_text_processor.adapt(train_raw.map(lambda context, target: context))\n",
        "# Here are the first 10 words from the vocabulary:\n",
        "context_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrrdIp-Ui4hH",
        "outputId": "d3bf9a1e-238e-4902-b8fb-6a4a04a12c9d"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', ',', 'the', 'and', '.', '[START]', '[END]', '(', ')']"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "target_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct,\n",
        "    max_tokens=max_vocab_size,\n",
        "    ragged=True)\n",
        "\n",
        "target_text_processor.adapt(train_raw.map(lambda context, target: target))\n",
        "target_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7W-r1jsfjAvG",
        "outputId": "8a67d6f2-748f-41f3-ebfb-2b7a652e7f79"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', 'اور', '۔', '[START]', '[END]', 'کے', 'سے', 'میں', 'ہے']"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Layers can convert a batch of strings into a batch of token IDs"
      ],
      "metadata": {
        "id": "WtPtRpxzMDwP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_tokens = context_text_processor(example_context_strings)\n",
        "example_tokens[:3, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D8YLxiy9jQp7",
        "outputId": "15f8a00f-7817-4b62-ff2c-d8378d7989de"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[6, 4, 24, 228, 46, 3, 1677, 642, 64, 10, 3, 2368, 2, 4, 24, 203, 2, 44,\n",
              "  27, 65, 3, 4597, 10, 2832, 2, 64, 10, 3, 715, 1059, 118, 2, 83, 4, 152, 5,\n",
              "  7]                                                                        ,\n",
              " [6, 57, 904, 23, 565, 2, 138, 57, 25, 281, 2, 35, 129, 68, 19, 1305, 50,\n",
              "  44, 27, 15, 346, 2, 12, 80, 2422, 25, 976, 13, 142, 1489, 2, 4, 2422,\n",
              "  2217, 46, 80, 353, 1363, 5, 7]                                         ,\n",
              " [6, 4, 8, 3, 155, 9, 66, 23, 3, 104, 440, 8, 51, 9, 70, 395, 8, 11, 171, 9,\n",
              "  19, 109, 5, 7]                                                            ]>"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The get_vocabulary method can be used to convert token IDs back to text:"
      ],
      "metadata": {
        "id": "wD2575yVMJcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "context_vocab = np.array(context_text_processor.get_vocabulary())\n",
        "tokens = context_vocab[example_tokens[0].numpy()]\n",
        "' '.join(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "K8hhPiT4jTds",
        "outputId": "28d7faab-9753-442a-c945-43bbc7728f95"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[START] and i saw when the lamb opened one of the seals , and i heard , as it were the noise of thunder , one of the four beasts saying , come and see . [END]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 133
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(context, target):\n",
        "    context = context_text_processor(context).to_tensor()\n",
        "    target = target_text_processor(target)\n",
        "    targ_in = target[:,:-1].to_tensor()\n",
        "    targ_out = target[:,1:].to_tensor()\n",
        "    return (context, targ_in), targ_out\n",
        "\n",
        "\n",
        "train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n",
        "val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"
      ],
      "metadata": {
        "id": "Z4ZrPJzWjZhF"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n",
        "    print(ex_context_tok[0, :10].numpy()) \n",
        "    print()\n",
        "    print(ex_tar_in[0, :10].numpy()) \n",
        "    print(ex_tar_out[0, :10].numpy()) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cFs-N9a1jc8m",
        "outputId": "b591065c-9a9d-41fb-b6de-78585bf55a30"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[   6    8   99   12   16 2319    2   76   15   27]\n",
            "\n",
            "[   4  729   10    6 5262    7    2   28  535  184]\n",
            "[ 729   10    6 5262    7    2   28  535  184    9]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "UNITS = 128"
      ],
      "metadata": {
        "id": "ffURrR3MjvBf"
      },
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Encoder Architecture"
      ],
      "metadata": {
        "id": "2DSbLSVAMW-R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, text_processor, units):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.text_processor = text_processor\n",
        "        self.vocab_size = text_processor.vocabulary_size()\n",
        "        self.units = units\n",
        "\n",
        "        # The embedding layer converts tokens to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n",
        "                                                   mask_zero=True)\n",
        "\n",
        "        # The RNN layer processes those vectors sequentially.\n",
        "        self.rnn = tf.keras.layers.Bidirectional(\n",
        "            merge_mode='sum',\n",
        "            layer=tf.keras.layers.GRU(units,\n",
        "                                # Return the sequence and state\n",
        "                                return_sequences=True,\n",
        "                                recurrent_initializer='glorot_uniform'))\n",
        "\n",
        "    def call(self, x):\n",
        "        shape_checker = ShapeChecker()\n",
        "        shape_checker(x, 'batch s')\n",
        "\n",
        "        # 2. The embedding layer looks up the embedding vector for each token.\n",
        "        x = self.embedding(x)\n",
        "        shape_checker(x, 'batch s units')\n",
        "\n",
        "        # 3. The GRU processes the sequence of embeddings.\n",
        "        x = self.rnn(x)\n",
        "        shape_checker(x, 'batch s units')\n",
        "\n",
        "        # 4. Returns the new sequence of embeddings.\n",
        "        return x\n",
        "\n",
        "    def convert_input(self, texts):\n",
        "        texts = tf.convert_to_tensor(texts)\n",
        "        if len(texts.shape) == 0:\n",
        "            texts = tf.convert_to_tensor(texts)[tf.newaxis]\n",
        "        context = self.text_processor(texts).to_tensor()\n",
        "        context = self(context)\n",
        "        return context"
      ],
      "metadata": {
        "id": "XmqNLqvyjxLR"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode the input sequence.\n",
        "encoder = Encoder(context_text_processor, UNITS)\n",
        "ex_context = encoder(ex_context_tok)\n",
        "\n",
        "print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n",
        "print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkVkDe76j3Eh",
        "outputId": "363aa418-8889-4af4-c85b-ce06c6cef1f4"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape (batch, s): (32, 83)\n",
            "Encoder output, shape (batch, s, units): (32, 83, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The attention layer"
      ],
      "metadata": {
        "id": "OIOF1U3jMb8J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CrossAttention(tf.keras.layers.Layer):\n",
        "    def __init__(self, units, **kwargs):\n",
        "        super().__init__()\n",
        "        self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n",
        "        self.layernorm = tf.keras.layers.LayerNormalization()\n",
        "        self.add = tf.keras.layers.Add()\n",
        "\n",
        "    def call(self, x, context):\n",
        "        shape_checker = ShapeChecker()\n",
        "\n",
        "        shape_checker(x, 'batch t units')\n",
        "        shape_checker(context, 'batch s units')\n",
        "\n",
        "        attn_output, attn_scores = self.mha(\n",
        "            query=x,\n",
        "            value=context,\n",
        "            return_attention_scores=True)\n",
        "    \n",
        "        shape_checker(x, 'batch t units')\n",
        "        shape_checker(attn_scores, 'batch heads t s')\n",
        "\n",
        "        # Cache the attention scores for plotting later.\n",
        "        attn_scores = tf.reduce_mean(attn_scores, axis=1)\n",
        "        shape_checker(attn_scores, 'batch t s')\n",
        "        self.last_attention_weights = attn_scores\n",
        "\n",
        "        x = self.add([x, attn_output])\n",
        "        x = self.layernorm(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "FtjYTxCxj-TM"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer = CrossAttention(UNITS)\n",
        "\n",
        "# Attend to the encoded tokens\n",
        "embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n",
        "                                  output_dim=UNITS, mask_zero=True)\n",
        "ex_tar_embed = embed(ex_tar_in)\n",
        "\n",
        "result = attention_layer(ex_tar_embed, ex_context)\n",
        "\n",
        "print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n",
        "print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n",
        "print(f'Attention result, shape (batch, t, units): {result.shape}')\n",
        "print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmiBb3v9kH7q",
        "outputId": "cea973ee-8574-44aa-9337-672f4edc3a0b"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context sequence, shape (batch, s, units): (32, 83, 128)\n",
            "Target sequence, shape (batch, t, units): (32, 69, 128)\n",
            "Attention result, shape (batch, t, units): (32, 69, 128)\n",
            "Attention weights, shape (batch, t, s):    (32, 69, 83)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_layer.last_attention_weights[0].numpy().sum(axis=-1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "336DkUP5kNV_",
        "outputId": "47ff61ac-d4ef-4526-f325-640fa3d05de4"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1.        , 1.        , 1.        , 0.99999994, 1.        ,\n",
              "       1.        , 1.        , 1.        , 1.        , 1.        ,\n",
              "       1.        , 1.        , 1.        , 0.99999994, 0.99999994,\n",
              "       1.        , 1.        , 0.99999994, 1.        , 0.99999994,\n",
              "       1.        , 1.        , 0.99999994, 1.        , 1.        ,\n",
              "       1.        , 0.99999994, 0.99999994, 0.99999994, 0.99999994,\n",
              "       0.99999994, 0.99999994, 0.99999994, 0.99999994, 0.99999994,\n",
              "       0.99999994, 0.99999994, 0.99999994, 0.99999994, 0.99999994,\n",
              "       0.99999994, 0.99999994, 0.99999994, 0.99999994, 0.99999994,\n",
              "       0.99999994, 0.99999994, 0.99999994, 0.99999994, 0.99999994,\n",
              "       0.99999994, 0.99999994, 0.99999994, 0.99999994, 0.99999994,\n",
              "       0.99999994, 0.99999994, 0.99999994, 0.99999994, 0.99999994,\n",
              "       0.99999994, 0.99999994, 0.99999994, 0.99999994, 0.99999994,\n",
              "       0.99999994, 0.99999994, 0.99999994, 0.99999994], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attention_weights = attention_layer.last_attention_weights\n",
        "mask=(ex_context_tok != 0).numpy()\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.pcolormesh(mask*attention_weights[:, 0, :])\n",
        "plt.title('Attention weights')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.pcolormesh(mask)\n",
        "plt.title('Mask');"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "cQpg9AldkR7L",
        "outputId": "832f3f59-9961-4fa9-d49c-219391e782ca"
      },
      "execution_count": 142,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Decoder architecture"
      ],
      "metadata": {
        "id": "08g0dSYIMh2Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun\n",
        "\n",
        "    def __init__(self, text_processor, units):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.text_processor = text_processor\n",
        "        self.vocab_size = text_processor.vocabulary_size()\n",
        "        self.word_to_id = tf.keras.layers.StringLookup(\n",
        "            vocabulary=text_processor.get_vocabulary(),\n",
        "            mask_token='', oov_token='[UNK]')\n",
        "        self.id_to_word = tf.keras.layers.StringLookup(\n",
        "            vocabulary=text_processor.get_vocabulary(),\n",
        "            mask_token='', oov_token='[UNK]',\n",
        "            invert=True)\n",
        "        self.start_token = self.word_to_id('[START]')\n",
        "        self.end_token = self.word_to_id('[END]')\n",
        "\n",
        "        self.units = units\n",
        "\n",
        "\n",
        "        # 1. The embedding layer converts token IDs to vectors\n",
        "        self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n",
        "                                                   units, mask_zero=True)\n",
        "\n",
        "        # 2. The RNN keeps track of what's been generated so far.\n",
        "        self.rnn = tf.keras.layers.GRU(units,\n",
        "                                       return_sequences=True,\n",
        "                                       return_state=True,\n",
        "                                       recurrent_initializer='glorot_uniform')\n",
        "\n",
        "        # 3. The RNN output will be the query for the attention layer.\n",
        "        self.attention = CrossAttention(units)\n",
        "\n",
        "        # 4. This fully connected layer produces the logits for each\n",
        "        # output token.\n",
        "        self.output_layer = tf.keras.layers.Dense(self.vocab_size)\n",
        "\n",
        "    \n",
        "@Decoder.add_method\n",
        "def call(self,\n",
        "         context, x,\n",
        "         state=None,\n",
        "         return_state=False):  \n",
        "    shape_checker = ShapeChecker()\n",
        "    shape_checker(x, 'batch t')\n",
        "    shape_checker(context, 'batch s units')\n",
        "\n",
        "    # 1. Lookup the embeddings\n",
        "    x = self.embedding(x)\n",
        "    shape_checker(x, 'batch t units')\n",
        "\n",
        "    # 2. Process the target sequence.\n",
        "    x, state = self.rnn(x, initial_state=state)\n",
        "    shape_checker(x, 'batch t units')\n",
        "\n",
        "    # 3. Use the RNN output as the query for the attention over the context.\n",
        "    x = self.attention(x, context)\n",
        "    self.last_attention_weights = self.attention.last_attention_weights\n",
        "    shape_checker(x, 'batch t units')\n",
        "    shape_checker(self.last_attention_weights, 'batch t s')\n",
        "\n",
        "    # Step 4. Generate logit predictions for the next token.\n",
        "    logits = self.output_layer(x)\n",
        "    shape_checker(logits, 'batch t target_vocab_size')\n",
        "\n",
        "    if return_state:\n",
        "        return logits, state\n",
        "    else:\n",
        "        return logits"
      ],
      "metadata": {
        "id": "AUra3HrskYwZ"
      },
      "execution_count": 143,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoder = Decoder(target_text_processor, UNITS)"
      ],
      "metadata": {
        "id": "7WZlFDrskgdy"
      },
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logits = decoder(ex_context, ex_tar_in)\n",
        "print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n",
        "print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4EI3_Qqkrbr",
        "outputId": "4f73b19e-26d4-49e3-9221-cb5638628896"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "encoder output shape: (batch, s, units) (32, 83, 128)\n",
            "input target tokens shape: (batch, t) (32, 69)\n",
            "logits shape shape: (batch, target_vocabulary_size) (32, 69, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Inference"
      ],
      "metadata": {
        "id": "fu5mHveZM4-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@Decoder.add_method\n",
        "def get_initial_state(self, context):\n",
        "    batch_size = tf.shape(context)[0]\n",
        "    start_tokens = tf.fill([batch_size, 1], self.start_token)\n",
        "    done = tf.zeros([batch_size, 1], dtype=tf.bool)\n",
        "    embedded = self.embedding(start_tokens)\n",
        "    return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"
      ],
      "metadata": {
        "id": "eNt41rhQkxG_"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Decoder.add_method\n",
        "def tokens_to_text(self, tokens):\n",
        "    words = self.id_to_word(tokens)\n",
        "    result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n",
        "    result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n",
        "    result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n",
        "    return result"
      ],
      "metadata": {
        "id": "Wd8z_lo0k-Yp"
      },
      "execution_count": 147,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@Decoder.add_method\n",
        "def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n",
        "    logits, state = self(\n",
        "    context, next_token,\n",
        "    state = state,\n",
        "    return_state=True) \n",
        "  \n",
        "    if temperature == 0.0:\n",
        "        next_token = tf.argmax(logits, axis=-1)\n",
        "    else:\n",
        "        logits = logits[:, -1, :]/temperature\n",
        "        next_token = tf.random.categorical(logits, num_samples=1)\n",
        "\n",
        "    # If a sequence produces an `end_token`, set it `done`\n",
        "    done = done | (next_token == self.end_token)\n",
        "    # Once a sequence is done it only produces 0-padding.\n",
        "    next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n",
        "\n",
        "    return next_token, done, state"
      ],
      "metadata": {
        "id": "vQonucxRlATX"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Setup the loop variables.\n",
        "next_token, done, state = decoder.get_initial_state(ex_context)\n",
        "tokens = []\n",
        "\n",
        "for n in range(10):\n",
        "  # Run one step.\n",
        "  next_token, done, state = decoder.get_next_token(\n",
        "      ex_context, next_token, done, state, temperature=1.0)\n",
        "  # Add the token to the output.\n",
        "  tokens.append(next_token)\n",
        "\n",
        "# Stack all the tokens together.\n",
        "tokens = tf.concat(tokens, axis=-1) # (batch, t)\n",
        "\n",
        "# Convert the tokens back to a a string\n",
        "result = decoder.tokens_to_text(tokens)\n",
        "result[:3].numpy()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v0EDkd61lChT",
        "outputId": "341454b3-4b8c-432a-e3f8-a71b29b0740e"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'\\xda\\xa9\\xdb\\x8c\\xd8\\xa7\\xdb\\x94 \\xda\\xa9\\xd9\\x85\\xd8\\xb1\\xdb\\x8c\\xda\\xba \\xd8\\xa8\\xda\\xbe\\xdb\\x8c\\xd8\\xac\\xdb\\x8c\\xda\\xaf\\xd8\\xa7 \\xd8\\xaa\\xd8\\xb1\\xd9\\x82\\xdb\\x8c \\xd9\\xbe\\xdb\\x8c\\xd9\\xbe \\xd8\\xb4\\xd8\\xa7\\xd9\\x84\\xdb\\x8c\\xd9\\x85 \\xd8\\xa8\\xd9\\x88\\xd9\\x84\\xd8\\xa7 \\xd9\\x86\\xd9\\x88\\xd8\\xb1 \\xd9\\x85\\xd9\\x88\\xd9\\x82\\xd8\\xb9\\xdb\\x81 \\xda\\xa9\\xd9\\x86\\xda\\xaf\\xd8\\xa7\\xd9\\x84\\xd9\\x88\\xda\\xba',\n",
              "       b'\\xd8\\xb3\\xd9\\x85\\xd8\\xac\\xda\\xbe\\xd8\\xa7\\xdb\\x8c\\xd8\\xa7 \\xd8\\xb3\\xd9\\x84\\xd8\\xb7\\xd9\\x86\\xd8\\xaa \\xd9\\x84\\xd8\\xa7\\xd9\\x8a\\xd9\\x94\\xd8\\xad\\xdb\\x81 \\xd8\\xaf\\xd8\\xa8\\xd8\\xa7\\xdb\\x8c\\xd8\\xa7 \\xd9\\x81\\xd8\\xb1\\xd9\\x85\\xd8\\xa7\\xd9\\x86\\xd8\\xa8\\xd8\\xb1\\xd8\\xaf\\xd8\\xa7\\xd8\\xb1 \\xd8\\xaa\\xdb\\x81\\xdb\\x81 \\xd8\\xaa\\xd8\\xb9\\xd8\\xb7\\xd9\\x84 \\xda\\x86\\xd9\\xb9\\xd8\\xa7\\xd9\\x86 \\xd8\\xa8\\xda\\x91\\xdb\\x92 \\xd8\\xb2\\xdb\\x8c\\xd8\\xb1\\xdb\\x81',\n",
              "       b'\\xd8\\xb1\\xd9\\x8a\\xd9\\x94\\xdb\\x8c\\xd8\\xb3 \\xd9\\x85\\xd8\\xaa\\xd9\\x88\\xd8\\xb3\\xd8\\xb7 \\xd8\\xb9\\xd8\\xa7\\xd8\\xaf\\xd9\\x84 \\xd9\\x85\\xd8\\xa7\\xd9\\x86\\xd9\\x88 \\xd9\\x85\\xd8\\xaa\\xd8\\xad\\xd9\\x85\\xd9\\x84 \\xda\\x86\\xd8\\xb3\\xd8\\xa7\\xdb\\x8c\\xd8\\xa7 \\xd8\\xaf\\xd9\\x88\\xda\\x91\\xd8\\xaa\\xd8\\xa7 \\xd8\\xaa\\xd8\\xac\\xd8\\xb1\\xd8\\xa8\\xdb\\x92 \\xd9\\x85\\xd8\\xb4\\xd9\\x85\\xd9\\x88\\xd9\\x84\\xd8\\xa7\\xd8\\xaa \\xd9\\x85\\xd9\\x88\\xd9\\x86\\xda\\xaf\\xdb\\x92'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 149
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Model"
      ],
      "metadata": {
        "id": "h3iOvVNZM-va"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(tf.keras.Model):\n",
        "    @classmethod\n",
        "    def add_method(cls, fun):\n",
        "        setattr(cls, fun.__name__, fun)\n",
        "        return fun\n",
        "\n",
        "    def __init__(self, units,\n",
        "                context_text_processor,\n",
        "                target_text_processor):\n",
        "        super().__init__()\n",
        "        # Build the encoder and decoder\n",
        "        encoder = Encoder(context_text_processor, units)\n",
        "        decoder = Decoder(target_text_processor, units)\n",
        "\n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "\n",
        "    def call(self, inputs):\n",
        "        context, x = inputs\n",
        "        context = self.encoder(context)\n",
        "        logits = self.decoder(context, x)\n",
        "\n",
        "        #TODO(b/250038731): remove this\n",
        "        try:\n",
        "            # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n",
        "            del logits._keras_mask\n",
        "        except AttributeError:\n",
        "            pass\n",
        "\n",
        "        return logits"
      ],
      "metadata": {
        "id": "ORpLPiWnlJUH"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "# logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "model = Translator(UNITS, context_text_processor, target_text_processor)\n",
        "\n",
        "logits = model((ex_context_tok, ex_tar_in))\n",
        "\n",
        "print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n",
        "print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n",
        "print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rtYz_BOlT2c",
        "outputId": "d5f78357-27c5-4b40-d08c-2000804813a5"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Context tokens, shape: (batch, s, units) (32, 83)\n",
            "Target tokens, shape: (batch, t) (32, 69)\n",
            "logits, shape: (batch, t, target_vocabulary_size) (32, 69, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training"
      ],
      "metadata": {
        "id": "hYglEd4zNFUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_loss(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "        from_logits=True, reduction='none')\n",
        "    loss = loss_fn(y_true, y_pred)\n",
        "\n",
        "    # Mask off the losses on padding.\n",
        "    mask = tf.cast(y_true != 0, loss.dtype)\n",
        "    loss *= mask\n",
        "\n",
        "    # Return the total.\n",
        "    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "AoMxefu5lgIz"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def masked_acc(y_true, y_pred):\n",
        "    # Calculate the loss for each item in the batch.\n",
        "    y_pred = tf.argmax(y_pred, axis=-1)\n",
        "    y_pred = tf.cast(y_pred, y_true.dtype)\n",
        "    \n",
        "    match = tf.cast(y_true == y_pred, tf.float32)\n",
        "    mask = tf.cast(y_true != 0, tf.float32)\n",
        "    \n",
        "    return tf.reduce_sum(match)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "EN7J3PZ9ls7M"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss=masked_loss, \n",
        "              metrics=[masked_acc, masked_loss])"
      ],
      "metadata": {
        "id": "ZOXOoqwllkhr"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = 1.0 * target_text_processor.vocabulary_size()\n",
        "\n",
        "{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n",
        " \"expected_acc\": 1/vocab_size}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dASdiWErloe8",
        "outputId": "da9c8292-648f-4d75-873f-a6269b5ad2d2"
      },
      "execution_count": 155,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'expected_loss': 9.2103405, 'expected_acc': 0.0001}"
            ]
          },
          "metadata": {},
          "execution_count": 155
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(val_ds, steps=20, return_dict=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEDW_hPMlxwr",
        "outputId": "1ab10a21-c7dc-42be-be91-2122e5218a70"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "20/20 [==============================] - 10s 48ms/step - loss: 9.2090 - masked_acc: 3.5706e-04 - masked_loss: 9.2090\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'loss': 9.208955764770508,\n",
              " 'masked_acc': 0.00035706369089893997,\n",
              " 'masked_loss': 9.208955764770508}"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_ds.repeat(), \n",
        "    epochs=100,\n",
        "    steps_per_epoch = 100,\n",
        "    validation_data=val_ds,\n",
        "    validation_steps = 20,\n",
        "    callbacks=[\n",
        "        tf.keras.callbacks.EarlyStopping(patience=5)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lv0l8_gTl8ho",
        "outputId": "4428903a-143f-4970-d7df-4518c2753ed5"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 37s 222ms/step - loss: 6.5703 - masked_acc: 0.0530 - masked_loss: 6.5703 - val_loss: 5.8668 - val_masked_acc: 0.0918 - val_masked_loss: 5.8668\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 15s 150ms/step - loss: 5.4586 - masked_acc: 0.1468 - masked_loss: 5.4586 - val_loss: 4.9845 - val_masked_acc: 0.1842 - val_masked_loss: 4.9845\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 4.8804 - masked_acc: 0.2009 - masked_loss: 4.8804 - val_loss: 4.6183 - val_masked_acc: 0.2179 - val_masked_loss: 4.6183\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 11s 106ms/step - loss: 4.5355 - masked_acc: 0.2306 - masked_loss: 4.5352 - val_loss: 4.4100 - val_masked_acc: 0.2329 - val_masked_loss: 4.4100\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 11s 105ms/step - loss: 4.2487 - masked_acc: 0.2556 - masked_loss: 4.2487 - val_loss: 4.2041 - val_masked_acc: 0.2544 - val_masked_loss: 4.2041\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 10s 100ms/step - loss: 4.1033 - masked_acc: 0.2743 - masked_loss: 4.1033 - val_loss: 4.1152 - val_masked_acc: 0.2671 - val_masked_loss: 4.1152\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 3.9902 - masked_acc: 0.2868 - masked_loss: 3.9902 - val_loss: 3.9263 - val_masked_acc: 0.2908 - val_masked_loss: 3.9263\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 11s 107ms/step - loss: 3.7267 - masked_acc: 0.3148 - masked_loss: 3.7269 - val_loss: 3.7982 - val_masked_acc: 0.3039 - val_masked_loss: 3.7982\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 3.5148 - masked_acc: 0.3386 - masked_loss: 3.5148 - val_loss: 3.7404 - val_masked_acc: 0.3146 - val_masked_loss: 3.7404\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 9s 93ms/step - loss: 3.4779 - masked_acc: 0.3437 - masked_loss: 3.4779 - val_loss: 3.7067 - val_masked_acc: 0.3174 - val_masked_loss: 3.7067\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 12s 116ms/step - loss: 3.3975 - masked_acc: 0.3538 - masked_loss: 3.3975 - val_loss: 3.5652 - val_masked_acc: 0.3417 - val_masked_loss: 3.5652\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 10s 103ms/step - loss: 3.0869 - masked_acc: 0.3887 - masked_loss: 3.0873 - val_loss: 3.5484 - val_masked_acc: 0.3391 - val_masked_loss: 3.5484\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 10s 104ms/step - loss: 2.9702 - masked_acc: 0.4023 - masked_loss: 2.9702 - val_loss: 3.4644 - val_masked_acc: 0.3520 - val_masked_loss: 3.4644\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.9424 - masked_acc: 0.4067 - masked_loss: 2.9424 - val_loss: 3.4842 - val_masked_acc: 0.3504 - val_masked_loss: 3.4842\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 2.9546 - masked_acc: 0.4067 - masked_loss: 2.9546 - val_loss: 3.3889 - val_masked_acc: 0.3566 - val_masked_loss: 3.3889\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 10s 95ms/step - loss: 2.5537 - masked_acc: 0.4572 - masked_loss: 2.5544 - val_loss: 3.4249 - val_masked_acc: 0.3662 - val_masked_loss: 3.4249\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.5431 - masked_acc: 0.4579 - masked_loss: 2.5431 - val_loss: 3.3097 - val_masked_acc: 0.3758 - val_masked_loss: 3.3097\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 2.5578 - masked_acc: 0.4554 - masked_loss: 2.5578 - val_loss: 3.3331 - val_masked_acc: 0.3788 - val_masked_loss: 3.3331\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 9s 88ms/step - loss: 2.4972 - masked_acc: 0.4666 - masked_loss: 2.4975 - val_loss: 3.2597 - val_masked_acc: 0.3847 - val_masked_loss: 3.2597\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 9s 92ms/step - loss: 2.1519 - masked_acc: 0.5195 - masked_loss: 2.1519 - val_loss: 3.3656 - val_masked_acc: 0.3773 - val_masked_loss: 3.3656\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 2.1939 - masked_acc: 0.5079 - masked_loss: 2.1939 - val_loss: 3.2762 - val_masked_acc: 0.3917 - val_masked_loss: 3.2762\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 10s 96ms/step - loss: 2.2494 - masked_acc: 0.4991 - masked_loss: 2.2494 - val_loss: 3.3252 - val_masked_acc: 0.3821 - val_masked_loss: 3.3252\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 9s 95ms/step - loss: 2.1061 - masked_acc: 0.5258 - masked_loss: 2.1063 - val_loss: 3.2851 - val_masked_acc: 0.3947 - val_masked_loss: 3.2851\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 9s 91ms/step - loss: 1.8726 - masked_acc: 0.5668 - masked_loss: 1.8726 - val_loss: 3.3214 - val_masked_acc: 0.3898 - val_masked_loss: 3.3214\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['loss'], label='loss')\n",
        "plt.plot(history.history['val_loss'], label='val_loss')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "-xLZ1n5wxdMF",
        "outputId": "dff1afa3-64f6-4b6a-9ee9-22cd0d68b342"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f29e2a74c70>"
            ]
          },
          "metadata": {},
          "execution_count": 158
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['masked_acc'], label='accuracy')\n",
        "plt.plot(history.history['val_masked_acc'], label='val_accuracy')\n",
        "plt.ylim([0, max(plt.ylim())])\n",
        "plt.xlabel('Epoch #')\n",
        "plt.ylabel('CE/token')\n",
        "plt.legend()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "dYPUXA_K4dLU",
        "outputId": "41e75073-763f-4dfc-f8b2-cd784cce19bb"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f290aba51c0>"
            ]
          },
          "metadata": {},
          "execution_count": 159
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEGCAYAAABo25JHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3dd1wUZ/7A8c/DAlKUKogCil1RQARrmiUmmjNqjMYz5RdN7+2Su7RLvJS79FzaJTGJJqYZozExiSUaS4omCljBriigFKkifff5/TELIoKgsiyw3/frtS9mZmdnvm4285155pnvo7TWCCGEcFxO9g5ACCGEfUkiEEIIByeJQAghHJwkAiGEcHCSCIQQwsE52zuAs9W+fXsdFhZm7zCEEKJFiY+PP6a1DqjtvRaXCMLCwoiLi7N3GEII0aIopQ7V9Z40DQkhhIOTRCCEEA5OEoEQQji4FnePoDbl5eWkpqZSUlJi71AE4ObmRkhICC4uLvYORQjRAK0iEaSmptKuXTvCwsJQStk7HIemtSY7O5vU1FS6du1q73CEEA3QKpqGSkpK8Pf3lyTQDCil8Pf3l6szIVqQVpEIAEkCzYj8txCi8eWeKLPZtltNIhBCiNZqX+ZxRr66li83HrbJ9iURCCFEM5ZZUMKNczbhYnLiwh7tbbIPSQQtTEVFhb1DEEI0kROlFdz0ySZyi8qYc+MgQv08bLIfSQSNaNKkScTExNCvXz9mz54NwPLlyxk4cCBRUVGMHj0agMLCQmbOnElERASRkZEsWrQIgLZt21Zta+HChcyYMQOAGTNmcMcddzBkyBD+/ve/s3HjRoYNG0Z0dDTDhw9n9+7dAJjNZh5++GH69+9PZGQkb731FqtXr2bSpElV2125ciVXXXVVU3wdQojzUGG2cPcXCew8epx3rh1IRIi3zfbVKrqPVvev7xNJOlLQqNsM7+TF01f2q3e9OXPm4OfnR3FxMYMGDWLixInceuut/PLLL3Tt2pWcnBwAnn32Wby9vdm+fTsAubm59W47NTWV9evXYzKZKCgo4Ndff8XZ2ZlVq1bx+OOPs2jRImbPnk1ycjJbtmzB2dmZnJwcfH19ueuuu8jKyiIgIIC5c+dy0003nd8XIoSwKa01T367g7W7s/jP5AhG9gm06f5aXSKwpzfffJPFixcDkJKSwuzZs7n44our+tP7+fkBsGrVKubPn1/1OV9f33q3PXXqVEwmEwD5+fnceOON7N27F6UU5eXlVdu94447cHZ2PmV/N9xwA5999hkzZ85kw4YNzJs3r5H+xUIIW3h79T7mb0rhnpE9mD64s8331+oSQUPO3G1h7dq1rFq1ig0bNuDh4cGIESMYMGAAu3btavA2qne7rNkP39PTs2r6n//8JyNHjmTx4sUkJyczYsSIM2535syZXHnllbi5uTF16tSqRCGEaH4Wxafy6so9TI4O5m+X9WqSfco9gkaSn5+Pr68vHh4e7Nq1iz/++IOSkhJ++eUXDh48CFDVNDRmzBjeeeedqs9WNg116NCBnTt3YrFYqq4s6tpXcHAwAB9//HHV8jFjxvD+++9X3VCu3F+nTp3o1KkTzz33HDNnzmy8f7QQolH9vu8Y/1i0jQt6+PPC1ZFN9kyOJIJGMnbsWCoqKujbty+PPvooQ4cOJSAggNmzZzN58mSioqKYNm0aAE8++SS5ubn079+fqKgo1qxZA8ALL7zA+PHjGT58OB07dqxzX3//+9957LHHiI6OPqUX0S233ELnzp2JjIwkKiqKL774ouq96667jtDQUPr27Wujb0AIcT52pRdwx6fxdA9oy7vXx+Dq3HSHZ6W1brKdNYbY2Fhdc2CanTt3ygGuHvfccw/R0dHcfPPNTbI/+W8iRMMdzS/mqnfWA/DNXcPp5OPe6PtQSsVrrWNre08aix1ATEwMnp6evPrqq/YORQhRQ0FJOTPnbqKwtIKv7xhmkyRQH0kEDiA+Pt7eIQghalFWYeHOz+LZl1nI3JmD6NvRyy5xSCIQQgg70Frz6Dfb+H1fNq9MjeKinrWOK98k5GaxEELYwWsr9/BNQhoPjenFlJgQu8YiiUAIIZrYlxsP89bqfUyLDeXeUT3sHY40DQkhRFPRWvPFxsM89V0iF/cK4Lmr+jeL8TskEQghRBMoKCnnsUXb+XH7US7q2Z7/XTcQF1PzaJSRRGAHbdu2pbCw0N5hCNEqWSya/63dh6+nK5eFBxHQro29Q2JLSh73fpnAkbwS/jG2D7df3A0nJ/tfCVSSRODAKioqpO6QaHU+Xp/MKz/tAeDJb3cwqIsfY/sHcXn/IIKbuI++xaL56LeDvLh8Fx283Fhw+zBiutRfZLKptb6jwLJHIX17424zKALGvVDn248++iihoaHcfffdAMyaNQtnZ2fWrFlDbm4u5eXlPPfcc0ycOLHeXRUWFjJx4sRaPzdv3jxeeeUVlFJERkby6aefkpGRwR133MGBAwcAePfdd+nUqRPjx49nx44dALzyyisUFhYya9asqmJ4v/32G9OnT6dXr14899xzlJWV4e/vz+eff06HDh0oLCzk3nvvJS4uDqUUTz/9NPn5+Wzbto3//ve/AHzwwQckJSXx+uuvn9fXK0Rj2Z9VyIvLdzGqTyCPXN6bFYnpLN+RzjM/JPHMD0lEhXhzef8gxvXvSNf2nvVv8DxkF5by8NdbWbM7i8v7deClq6Pw9nCx6T7PVetLBHYwbdo0HnjggapEsGDBAlasWMF9992Hl5cXx44dY+jQoUyYMKHeG0Nubm4sXrz4tM8lJSXx3HPPsX79etq3b19VUO6+++7jkksuYfHixZjNZgoLC+sd36CsrIzKMh25ubn88ccfKKX48MMPeemll3j11VdrHTPBxcWF559/npdffhkXFxfmzp3L+++/f75fnxCNosJs4aEFW3F3NfHC5AgCvdzo29GLBy7txcFjJ1i+I53liem8tHw3Ly3fTe8O7RjbP4ix/YPoE9SuUW/abtifzQNfbSb3RDnPTOzHDUO7NIubwnVpfYngDGfuthIdHU1mZiZHjhwhKysLX19fgoKCePDBB/nll19wcnIiLS2NjIwMgoKCzrgtrTWPP/74aZ9bvXo1U6dOpX17Y8zSyrEGVq9eXTW+gMlkwtvbu95EUFn8DowBb6ZNm8bRo0cpKyurGjuhrjETRo0axQ8//EDfvn0pLy8nIiLiLL8tIWzjvXX72ZqSx9vXRhPo5XbKe13be3LniO7cOaI7R/KKWZGYzrId6by5ei9v/LyXMH8PLu8fxKjegUSF+uDmYjqnGMwWzVur9/Lmz3sJ8/dkzoxB9Otku5HFGotNE4FSaizwBmACPtRav1Dj/RnAy0CaddHbWusPbRmTrUydOpWFCxeSnp7OtGnT+Pzzz8nKyiI+Ph4XFxfCwsJOG2OgNuf6ueqcnZ2xWCxV82ca2+Dee+/loYceYsKECaxdu5ZZs2adcdu33HIL//73v+nTp4+UtBbNRuKRfN74eS/jIzsyPrLTGdft5OPOzAu6MvOCrmQdL2VlUgbLdhzlo18P8v66A7g6OzEg1IchXf0Y0tWfgV188HCt/1CZUVDC/fM388eBHCZHB/PspP54tmkZ59o2i1IpZQLeAcYAqcAmpdQSrXVSjVW/0lrfY6s4msq0adO49dZbOXbsGOvWrWPBggUEBgbi4uLCmjVrOHToUIO2k5+fX+vnRo0axVVXXcVDDz2Ev78/OTk5+Pn5MXr0aN59910eeOCBqqahDh06kJmZSXZ2Nm3btuWHH35g7Nixde6vcmyDTz75pGp55ZgJlfcDcnNz8fX1ZciQIaSkpJCQkMC2bdvO5ysTolGUVpj524Kt+Hi48uzE/mf12YB2bbh2SGeuHdKZ/OJyNh7MYePBbP48mMM7a/bx1up9ODsp+gd7M6SbH0O6+hHTxQ9v91Pb+tfszuRvC7ZSUm7m1alRXG3nJ4XPli3T1WBgn9b6AIBSaj4wEaiZCFqFfv36cfz4cYKDg+nYsSPXXXcdV155JREREcTGxtKnT58Gbaeuz/Xr148nnniCSy65BJPJRHR0NB9//DFvvPEGt912Gx999BEmk4l3332XYcOG8dRTTzF48GCCg4PPuO9Zs2YxdepUfH19GTVqVNUgOk8++SR33303/fv3x2Qy8fTTTzN58mQArrnmGrZs2dKgITaFsLU3Vu1lV/px5syIxdfT9Zy34+3uwpjwDowJ7wBAYWkF8YdyjcRwIIc5vxlXDEpB3yAvBnf1Y2g3PxIO5zH7lwP0CWrH29cOpEdg28b6pzUZm41HoJSaAozVWt9inb8BGFL97N/aNPQfIAvYAzyotU6pZVu3AbcBdO7cOabm2bXUvm9a48eP58EHH2T06NF1riP/TURTiD+Uy9T31jM1JpQXp0TadF8l5WY2H85j48Ec/jyYTcLhXErKjSbY64d25sm/hJ/zvYWm0JzHI/ge+FJrXaqUuh34BBhVcyWt9WxgNhgD0zRtiKJSXl4egwcPJioq6oxJQIimUFxm5uGvt9LR250nx9v+pMPNxcSw7v4M6+4P9KSswsL2tHyUgoGdW/bVsS0TQRoQWm0+hJM3hQHQWmdXm/0QeMmG8TQr27dv54YbbjhlWZs2bfjzzz/tFFH9fHx82LNnj73DEAKAF5fv4uCxE3xx6xDauTV9/3xXZ6dm+XDYubBlItgE9FRKdcVIAH8Frq2+glKqo9b6qHV2ArDzXHemtW7W/XRrioiIYMuWLfYOwyZa2vCnouVZv+8YH69PZsbwMIZ3b2/vcFo8myUCrXWFUuoeYAVG99E5WutEpdQzQJzWeglwn1JqAlAB5AAzzmVfbm5uZGdn4+/v36KSQWuktSY7Oxs3N7f6VxbiHBSUlPPIwm10a+/JP8Y2rBOGODOb3iPQWi8FltZY9lS16ceAx853PyEhIaSmppKVlXW+mxKNwM3NjZCQltV9TrQcz36fxNH8YhbdORx31+Z7c7YlsffN4kbh4uJS9USsEKL1WpWUwdfxqdw9sjvRLfwGbXPSPIphCyFEPXJOlPHoN9vpE9SO+0f3snc4rUqruCIQQrR+//xuB/nFZXx682BcneUctjHJtymEaPaWbD3Cj9uO8sClvejb0cve4bQ6kgiEEM1aZkEJ//x2B9Gdfbj94m72DqdVkkQghGi2KswWHv1mO6UVRjE352Yyxm9rI/cIhBDNSnGZmV/3ZvFTUgY/78wgt6icp68Mp1tAyyvm1lJIIhBC2F3uiTJW78pkRWI6v+zNoqTcQjs3Z0b3CWRcREcus1YEFbYhiUAIYRepuUWsTMrgp8QMNibnYLZogrzcuCY2lMvCgxjSzQ8XaQpqEpIIhHBgZovm+R93knQ0nwqzptyiqTBbrNPWv2YL5WZNRbX5CovGxaTwcXfFx8MFb3cXfDxcTs5Xm/ZxN+a93V0oKK5g1c4MViSmk3ikAICegW2545JuXBYeRESwN05OUiamqUkiEMKBvbduP3N+P8iAUB88XE14mJxwcVI4mxTOJidcTU44OxnTLiaFs5P1r0lRbtbkFZWRV1ROXnE5yceKyCvOI7eonLIKS537VAqiQ314bFwfxoR3kLb/ZkASgRAOaktKHq+v3MNfIjvy9vToRi3YWFJutiYIa6IoKie/uAwnpbikV8Bpg8sL+5JEIIQDKiyt4P75mwls14Z/T4po9Kq9bi4mgrxNBHnLAb8lkEQghAP615JEUnKK+PLWoXh7NP2gLqJ5kVvyQjiYH7cd5ev4VO4a0YMh3fztHY5oBiQRCOFA0vKKeeybbQwI9eH+S3vaOxzRTEgiEMJBmC2aB7/agtmieeOvA6SPvqgi9wiEcBDvrdvPxoM5vDwlki7+nvYORzQjckoghAOo3lV0SowMIypOJYlAiFbuhI27ioqWT5qGhGjlZklXUVEPuSIQohWTrqKiISQRCNFKSVdR0VCSCIRohaSrqDgbco9AiFZIuoqKsyGnCUK0Mlulq6g4S5IIhGhFpKuoOBfSNCREM2OxaDKPl3KssBStz+6zc34/yGHpKirOkk0TgVJqLPAGYAI+1Fq/UMd6VwMLgUFa6zhbxiSEvVWYLaQXlJCaW0xabrHxN6+ItDxj+mheCWXmukf4qs89I6WrqDg7NksESikT8A4wBkgFNimllmitk2qs1w64H/jTVrEIYS/5ReV8v+0ICYdzqw786QUlmC2nnuoHtGtDiK87EcHejOvfkWBfdwLbtcF0lk07nm2cGdLVrzH/CcIB2PKKYDCwT2t9AEApNR+YCCTVWO9Z4EXgERvGIkSTMVs0v+07xsL4VFYkplNWYaGDVxu6+HkyuKsfwT7uhPi6E+zrToivBx293XBzMdk7bOHAbJkIgoGUavOpwJDqKyilBgKhWusflVJ1JgKl1G3AbQCdO3e2QahCnL8DWYUsjE/lm4Q00gtK8PFwYfqgUKbEhNI/2Etu3Ipmy243i5VSTsBrwIz61tVazwZmA8TGxp7l7TMhbKegpJwftx1lYXwq8YdycVIwoncgT10Zzui+gbRxljN9UU3mLtixEA7/AW07gF9X8A0D367GdNsgcGr6zpy2TARpQGi1+RDrskrtgP7AWuuZUhCwRCk1QW4Yi+bMYtGs35/NwvgUliemU1JuoUdgWx4b14erooMJ9JIB21uczF2w5TMwV0C3S6DLBeDm1TjbzjsMOxbB9kWQsR2UEwRFQt4hSPwGdLWOAc5u4NPFSA5+XY0EUTnt0wVcbPPbsmUi2AT0VEp1xUgAfwWurXxTa50PtK+cV0qtBR6WJCCaK601H/56kLm/H+RIfglebs5MiQlhSkwoUSHe0vTT0pQXQ9ISiJ8LhzeAkws4OcOf74IyQUgsdBthvIJjwdm14dsuzIKkb2H715Bi7QcTMgjGvgj9roJ2HYxl5nIjUeQmQ+5ByDlonU6G5N+g/MSp2/3LqzDolvP8h5/OZolAa12hlLoHWIHRfXSO1jpRKfUMEKe1XmKrfQvR2CwWzazvE5m34RDDu/vz2BV9GRPeQW7y2prFAsU54OEPjZVoM3dB/Mew9UsoyQO/7jDmWRhwLbRpBykb4cBa4/XLy7DuRXDxhC7DTyaGwPDTm3BK8mHnD0bTz4F1oM3GeqP+Cf2vNs7qazK5gH9341WT1nDimJEgcpONJBEc0zjfQQ1Kn+0TK3YWGxur4+LkokE0HbNF8/g32/kqLoVbL+rK41f0lbP/xmauMA54Wbusrz3G32N7oaIY3H2hUzR0Gmj8DR4IXp0avv3yYkj6DuLmQsofxtl/+ASImQFhF9WdZIrzjDPzA2vh4Do4tsdY7hkAXS8xkoKrp9HEs+cnMJcaTTgRU6D/FOgQfn7fSyNSSsVrrWNrfU8SgRB1qzBbeGThNhZvTuPeUT14aEwvSQLno6IUsvdZD/a7T76y94Gl/OR6XiEQ0BsC+hgH/KxdcGQLZCYZZ9pg3FitTAqVCcKzxoN0mTurnf3nG2f/MTOMs3/P9py1/DQjIVReMRRmGMs9A6H/ZOPgHxLbeFcvjehMiUBKTAhRh3KzhQfmb+HH7Ud5+LJe3DNKavqfxmKG4lyjCaPoGJzIsk5nV1tWY77q5qgyboQG9IFel1sP/L2hfS+jiaY2ZUWQsQPSEuDIZjiSAHuWA9YTWp/ORkIIDIf9a87u7L8hvIONJDLgWqPpJmuXcdUQOhicWm4zoVwRCFGL0gozd3++mVU7M3jyL3255aJu9g7J/szlkBZvHGAPrIXsvVCUQ9VBuCY3b/Bob5x5e7Q3ztbbBp084Pv3ABf384+rpACObj2ZGI5sNtrU/XsYB/+o6ed29t/KyBWBEGehuMzM7Z/F88ueLJ6d2I8bhoXZOyT70NpoE6888Cf/BmXHAWWcdfedYLSVe7Y3buZWHfCt86YmKnrn5gVdLzJelUqPg2vbZtlE0xxJIhCimhOlFdz8ySb+PJjDS1dHcs2g0Po/1JoczzjZ/n1gLRw/Yiz37QqRU42bo2EXgUczr2dUV9OSqJUkAiGsCkrKmTl3E1tS8nj9mgFMig62d0i2V1oIh9bDAetZf6a1FJi7n/FgVbcRxss3zF4RiiYgiUAIIK+ojP+bs5GkIwW8PT2acREd7R2SbZgrjHb0yuae1I1gqQBTG+gyDCKnGQf+oEi7lDoQ9iGJQDi87MJSrv9oI/szC3nv+hguDe9g75AaT2U7f2VTT/JvUFoAKOgYBcPuMQ78nYc2zo1b0SJJIhAOLbOghOs+/JOU3CI+vDGWi3sF2Duk83c83Xiy9bR2/jCjr3u3kdD14ubfzi+ajCQC4bCO5BVz3Yd/klFQwsczBzO0pY3qZbFAforRrp+ZZDw8dXQbHNttvO/uazz92n2k8be2EgdCIIlAOJgKs4XNKXms253FooRUCksq+PTmwcR0seHZcUWp8TCVq4fRpfFsu1VqbTyolZkEGdUO+lm7oKzw5HreoRDY13jYqdsIaecXDSaJQLR6R/OLWbc7i3V7svht3zGOl1RgclLEdPbln+PDiQjxbvydWixw6HfYvgASv4PS/JPvObkY9Wmqv1wqpz1OzmuzUX4hM8l4MreSh7/x5OyA64wDf4d+xgNabjb4dwiHIIlAtDqlFWbiknNZtyeLdbuz2J1xHICO3m78JaIjl/QK4IKe7fFys8EDT+k7jIP/9oVQkGYc0PteaZQgqCgxSiSUFUJ5EZSdOPkqL4LCdOu89T2AgF7Q5y/GgT+wLwT2g7at4D6GaFYanAiUUsOBsOqf0VrPs0FMQpwVrTWHc4qqDvzr92dTXG7G1eTEoK6+XB3ThxG9A+kZ2NY2BePyU42689u+hsxEo6Z999Ew5hnoPc44wxeiGWtQIlBKfQp0B7YA1tJ/aEASgWgSFovmaEEJh46dIDm7iEPZJziUXUSy9W9xufGzDPVzZ0pMCCN6BzC0mz+eber4iVsssG+l0Yfe3c/oQePuB+4+DWvDL841yhpv+xoO/WYsCxkMV7xiDDwitW1EC9LQK4JYIFy3tAp1osU5UVpB/KFcDmWfPOAnZxdxOKeIsoqTQ/q5mpwI9XMnzN+T4d3b0y3Akwt6tCfM36P+s/6cA/Dt3XB4fe3vt/EyEkJVgvA9Od3GyxjNau9PYC4D/54w8gmj/ryfFKYTLVNDE8EOjDGFj9owFuHg1u3J4rFF2ziSXwKAm4sTYf6edA/wZHSfQDr7exDm70kXfw86ertjcjrLZh6LBeI+gpVPGTdsJ7wFQRFGBc3iXONVlGOMiFV9OjfZmC7JB7Qx6PigWyDyGug4QAqbiRavoYmgPZCklNoIlFYu1FpPsElUwqHkF5fz/I9JLIhLpXuAJ3NmxNKvkzeB7do0Xpt+3mH47m44+At0HwUT3jZqy58Ni9lIBm7eLbr2vBA1NTQRzLJlEMJxrd6VwePf7CDzeAl3jujO/aN7Nu44wFpDwjxY8QSg4co3YOCN53YW72SSp3FFq9SgRKC1XqeU6gL01FqvUkp5YAxIL8Q5yS8q518/JPJNQhq9OrTl/RsuICrUp5F3kgbf3wf7Vhmlkye+A75dGncfQrQCDe01dCtwG+CH0XsoGHgPGG270ERrtTIpg8cXbyfnRBn3jurBPaN60Ma5ka8Cts6HZf8wxsEd97LRpi9P2QpRq4Y2Dd0NDAb+BNBa71VKBdosKtEq5Z4oY9b3iXy35Qh9O3oxd8Yg+gc38tOwxzPghwdg91IIHQqT/gf+3Rt3H0K0Mg1NBKVa67LKG3dKKWfqHKhUiNMt33GUJ7/dQV5ROQ9c2pO7RvTA1bkRz9C1hh2LYOnDxpO5lz0PQ++Um7pCNEBDE8E6pdTjgLtSagxwF/C97cISrUV2YSlPLUnkx21H6dfJi3k3DSG8k9e5b1Bro55+UbbRpbMo23jtXgY7l0BwDEx6zyjNIIRokIYmgkeBm4HtwO3AUq31BzaLSrQKy7Yf5Ylvd3C8pJyHL+vF7Zd0x8V0hqsAcwWk/Anp204e4Gse8IuyjaeBazK5wuinYPj9YJISWkKcjQZ3H9VaPwV8AKCUMimlPtdaX2e70ERLVW628O+lO5n7ezKRId68PGUovYPqGEy8KMfo1bNnufG3xFqlUzlZn+b1N15+3SBk0Mn5U15+0DZQavoIcY4amghClVKPaa3/o5RyBRZg1B0S4hQZBSXc/XkCcYdymXlBGI9f0ffUqwCtjVr6e5YbZRpS/gRtAc9A6HMl9LoculxglHWQXj5CNImGJoKbgM+VUo8BI4FlWuvXbReWaIk27M/m3i8TKCoz8+b0aCZEdTLeKC+B5F9hzwrjlX/YWN4xCi5+xDj4d4yWA78QdnLGRKCUGlht9g3gfeB3jJvHA7XWCfV8fqz1cybgQ631CzXevwOja6oZKARu01onnfW/QtiV1prZvxzgpRW7CfP34Mtbh9LTW8Pmz2DXj8a4ueVF4OJhjJd78d+g52Xg1cneoQshAHWmgqJKqTVn+KzWWo86w2dNwB5gDJAKbAKmVz/QK6W8tNYF1ukJwF1a67FnCjg2NlbHxcWdaRXRhApKynnk662sSMxgfP8AXo7Oxn3n10YCqCgB787GGX+vsRB2Ibi42TtkIRySUipeax1b23tnvCLQWo88j/0OBvZprQ9Yg5gPTASqEkFlErDyRJ5NaFF2px/njk/jaJuXxPc9E+l/dCVqX6bRvh99PURNN7pzSnVOIZq1hpaY8AaeBi62LloHPKO1zq/7UwQDKdXmU4EhtWz7buAhwBWo9QpDKXUbRokLOnfu3JCQhY2t2JDA9mUf8KHTr3R3SYE0F+g9FiL/ajT7OLvaO0QhRAM19GbxHIwxCa6xzt8AzAUmn28AWut3gHeUUtcCTwI31rLObGA2GE1D57tPcY5KC6lIXMKh1R8x5ng8lztpyjoNgugHjVG5pDKnEC1SQxNBd6311dXm/6WUqq/7aBoQWm0+xLqsLvOBdxsYj2hKxzPg52ew7FiEc0UxLpYAfgu5iWFX3YVrQA97RyeEOE8NTQTFSqkLtda/ASilLgCK6/nMJqCnUqorRgL4K3Bt9RWUUj211nuts38B9iKaj8oqnssfxVJWxGJ9CYstF3LtlGu4IlJ6/CD5OtkAABQXSURBVAjRWjQ0EdwBzLPeKwDIpZYmnOq01hVKqXuAFRjdR+dorROVUs8AcVrrJcA9SqlLgfKGbFM0ofw0ir65F49DP5No6sO9xbdgCujFezfE0D2grb2jE0I0ooYmggKtdZRSyguM3j7WM/0z0lovBZbWWPZUten7zyZYYXtHcovYt/wdYva8hrKYmVXxf+zsMI2ZA0K4OiYED1ep4yNEa9PQ/6sXAQNrdPdcCMQ0fkiiqWUdL2XZjqP8GZ/A9IxXuNiUyDaXSHYOep7bhwyio7e7vUMUQthQfU8W9wH6Ad5Kqeo9hLwAeTKoBcsvKmdFYjpLth5hw/5Mrndayasu83FydebYRS8SefFtRErJByEcQn1XBL2B8YAPcGW15ceBW20VlLCdTck5vL/uAOv2ZFJu1gz3yWVd+9mEHN8KPS6F8f+lvU9o/RsSQrQa9SUCD+BhYLbWekMTxCNsZHtqPq/8tJt1e7Jo39aVGUNDmWlaSseE11C0gUnvGk8Cy1PAQjic+hJBZ+BrwEUp9TOwDNioz1SgSDQrezOO8+pPe1iemI6PhwuPjuvDjB7FuC29D9LiofdfYPxr0C7I3qEKIeykvlpDLwIvKqXaAZdilKN+Tym1E1gOrNBaZ9g+THG2DmcX8d9Ve1i8JQ0PFxMPjezMLUH78Ng1C9YtAzcvmDIH+k2WqwAhHFyDeg1prY8Di60vlFLhwDhgHnC5zaITZy09v4S3Vu/lq00puDhpno88xtUuG2iT8KMx1q9nIAy+FS76G3i2t3e4QohmoL5eQ9drrT+zTl+gtf4dQGudpJQapbWWJNBMZBeW8u7a/Xz6RzL92ce8TtsYUrwO0+5MaOMFfSdAxBQIu0jG9BVCnKK+I8JDwGfW6beA6gPV3AS8bYugRMMVlJTz4S8HWP3bb1xm+ZXf3TfSvjwNcl2NcQAiphrVQF3kWQAhRO3qSwSqjuna5kUT0lqz8LdtHP75Ay63/MpDTslokxMq9GKIeBz6jAd3H3uHKYRoAepLBLqO6drmRRPJzDvBsnkvMDH7I3zUCYo6DICYF1D9rpLeP0KIs1ZfIuijlNqGcfbf3TqNdb6bTSMTtVq/dik+ax/nRg6S7heLnvZfPIIi7B2WEKIFqy8RRAEdOHWkMTDGGUi3SUSiVgXHjrDz04cYnr+MbCd/Mi79H0HDrpWun0KI81ZfIngdeExrfaj6QmsV0tc5teyEsAVzBQeWvUFA3CsM1KXEhdxA1HXP4+LhXf9nhRCiAepLBB201ttrLtRab1dKhdkkIlGl9MDv5H59H92K9xFniqLtpNeIjYi1d1hCiFamvkRwpm4n0h/RVo6nk/fdo/jsW4xZ+/NV1+eYMP1O3NtI/38hROOr78gSp5S6VWv9QfWFSqlbgHjbheWgzOWY/3gf8+p/41FRylzTZHpOmcW08C72jkwI0YrVlwgeABYrpa7j5IE/FnAFrrJlYA7FYoH9P1O27Alcc3bzqzmKdd0f5v5rxuLj4Wrv6IQQrVx9RecygOFKqZFAf+viH7XWq20emSMozoUtX8CmjyBnP5k6gJfUI4yePIOno0PsHZ0QwkE0tOjcGmCNjWNxHEe3wsYPYPtCqCjmsGcEr5bdRW7YOF6cJkNDCiGaltx9bCrlJZD0HWz6AFI3gYsHpeFT+Ff6ML447MMtF3bltSv6YnKS5wKEEE1LEoGt5R6C+LmQMA+KssG/B4x9gQPBV3LT/L0cySvh5Sn9mRorw0MKIexDEoEtWCywfzVs+hD2LDee/u19BQy6BbqNYM3uLO77cDNtXJz48rYhxHTxs3fEQggHJomgseUdhi+mQWYSeAYYA8DEzgTvELTWfPDrAf6zbBd9g7z44MZYgn3kfoAQwr4kETSmrN0wbxKUn4DJH0D4JHA2un+WlJt5YvEOFiWkckVEEK9MjcLDVb5+IYT9yZGosRzZDJ9dDcoEM5ZCUP+qtzKPl3D7p/FsPpzHA5f25L5RPXGSm8JCiGZCEkFjSP7daA5y94X/+xb8u1e9tSMtn1vnxZFXVM671w1kXERHOwYqhBCnc7LlxpVSY5VSu5VS+5RSj9by/kNKqSSl1Dal1M9KqZZXS2HPCvhsMnh1gptXnJIEftx2lCnvrUcBC+8cJklACNEs2SwRKKVMwDvAOCAcmK6UCq+x2mYgVmsdCSwEXrJVPDaxfSHMvxYC+sDMZUYyACwWzWsr93D3Fwn06+TNd/dcSL9OUjZaCNE82fKKYDCwT2t9QGtdBswHJlZfQWu9RmtdZJ39A2g5dRU2fQSLboHQoXDj9+DpDxhJ4N75m3nz571MjQnhi1uHENCujZ2DFUKIutnyHkEwp45slgoMOcP6NwPLantDKXUbcBtA586dGyu+c/fra/Dzv6DXWJj6Mbic7AI6b0MyP247yiOX9+auEd1RMoKYEKKZs+k9goZSSl2PUdX05dre11rP1lrHaq1jAwICmja4UwOBlU8ZSSBiKkz77JQkcCj7BC8u382I3gGSBIQQLYYtrwjSMMY2rhRiXXYKpdSlwBPAJVrrUhvGc34sZvjhQUj4xHhCeNzL4HQyj1osmkcWbsPZpPjP5AhJAkKIFsOWVwSbgJ5Kqa5KKVfgr8CS6isopaKB94EJWutMG8ZyfirKYNHNRhK46G9wxSunJAEwmoQ2Hszhn+PDpXqoEKJFsdkVgda6Qil1D7ACMAFztNaJSqlngDit9RKMpqC2wNfWM+jDWusJtorpnJQVwYIbYN8qGPMsXHDfaatUNgmN7B3A1JiWc79bCCHAxg+Uaa2XAktrLHuq2vSlttz/eSsvNp4ROPwHXPkmxNx42iqnNglFSpOQEKLFkSeLz2TbV3B4g1E3KPKaWlf5ZIPRJPTylEiCvN2aNj4hhGgEzaLXULOVMA8Cw40eQrVIPnaCF5fvYmTvAKZIk5AQooWSRFCX9B2QFg8D/88YT6AGi0Xz94XbcDE5SZOQEKJFk0RQl82fgskVIqfV+vYnG5LZmJzDU+PDpUlICNGiSSKoTXkJbJ0Pfa8Ej9NHD6tsEhrVJ1CahIQQLZ4kgtrs+gFK8oxmoRqqNwn9+yp5cEwI0fJJIqhNwifg0wXCLj7trY/XG01CT1/ZT5qEhBCtgiSCmnIOwMFfYOANpz09fPDYCV5aYTQJXT0w2E4BCiFE45JEUNPmz0A5wYDrTllsNAltlSYhIUSrI4mgOnMFbP4ceoypGmSm0sfrk9mUnCtNQkKIVkcSQXX7VkJh+mk3iaVJSAjRmkkiqC5hHngGQq/LqxZVNgm5mpykvLQQolWSRFCp4KgxEP2Aa8HkUrV4brUmoQ5e0iQkhGh9JBFU2voFaPMpzUJpecW8vGIXo/sEMlmahIQQrZQkAgCLBRI+hS4Xgn/3qsVfbUqhtMLCrAn9pElICNFqSSIAOPQb5B485WrAbNEsjEvh4p4BhPp52DE4IYSwLUkEYNwkbuMN4ScHR/t93zGO5JdwTWzoGT4ohBAtnySCohxIWmIMPONycqzhr+JS8PVw4dLwQDsGJ4QQtieJYPvXYC49pVko90QZKxMzmBQdTBtnkx2DE0II23PsRKA1xH8CHQdAx8iqxd9tSaPMbJFmISGEQ3DsRHAkATITT7ka0FrzVVwqkSHe9O3oZcfghBCiaTh2IkiYB87uEDGlalHikQJ2Hi1gqlwNCCEchOMmgrITsH0R9LsK3LyrFn+1KYU2zk5MiOp0hg8LIUTr4biJIPFbKDt+SrNQSbmZ77akMa5/EN7uLmf4sBBCtB6OmwgS5oF/T+g8tGrRisR0Ckoq5CaxEMKhOGYiyNoNKX8YVwPVSkcsiEsh1M+dod387RicEEI0LcdMBAnzwMkZoqZXLUrJKeL3fdlMjQnFyUnqCgkhHIfjJYKKMtj6JfS+AtoGVC3+Oj4VpeDqmBA7BieEEE3PpolAKTVWKbVbKbVPKfVoLe9frJRKUEpVKKWm1LaNRrd7KRRlw8AbqxZVFpi7qGcAwT7uZ/iwEEK0PjZLBEopE/AOMA4IB6YrpcJrrHYYmAF8Yas4TpMwD7xCoPvIqkXr91cWmJOrASGE47HlFcFgYJ/W+oDWugyYD0ysvoLWOllrvQ2w2DCOk/IOw/7VEH09OJ2sIfTVphR8PFwYE96hScIQQojmxJaJIBhIqTafal121pRStyml4pRScVlZWece0ebPjb/R11Utyisq46fEDCYNkAJzQgjH1CJuFmutZ2utY7XWsQEBAfV/oDYWM2z+DLqPAp/OVYu/3SwF5oQQjs2WiSANqH50DbEus4/9a6Ag9ZQniQEWxKUSEexNeCcpMCeEcEy2TASbgJ5Kqa5KKVfgr8ASG+7vzApSwTfM6DZqtSMtn6SjBXKTWAjh0GyWCLTWFcA9wApgJ7BAa52olHpGKTUBQCk1SCmVCkwF3ldKJdoqHmJmwL2bwdm1atGCOGuBuQHndOtCCCFaBWdbblxrvRRYWmPZU9WmN2E0GTUNp5N5r6TczLeb0xgrBeaEEA6uRdwstgUpMCeEEAaHTQRfx6US4uvOMCkwJ4RwcA6ZCFJyivh9/zEpMCeEEDhoIlgYnwrAFOktJIQQjpcILBbNwvhULuzRXgrMCSEEDpgIft9/jLS8YrlJLIQQVg6XCBbEpeLj4cJl/aTAnBBCgIMlgryiMlYkpkuBOSGEqMahEsF3W45QViEF5oQQojqHSgQL4lLoH+wlBeaEEKIah0kEO9LySTxSIFcDQghRg8MkglU7M3B1dmJilBSYE0KI6mxadK45uX90TyYNCMbbQwrMCSFEdQ5zRaCUIqy9p73DEEKIZsdhEoEQQojaSSIQQggHJ4lACCEcnCQCIYRwcJIIhBDCwUkiEEIIByeJQAghHJwkAiGEcHCSCIQQwsFJIhBCCAcniUAIIRycJAIhhHBwkgiEEMLBSSIQQggHZ9NEoJQaq5TarZTap5R6tJb32yilvrK+/6dSKsyW8QghhDidzRKBUsoEvAOMA8KB6Uqp8Bqr3Qzkaq17AK8DL9oqHiGEELWz5RXBYGCf1vqA1roMmA9MrLHOROAT6/RCYLRSStkwJiGEEDXYcqjKYCCl2nwqMKSudbTWFUqpfMAfOFZ9JaXUbcBt1tlCpdTuc4ypfc1tOyj5Hk6S78Ig34OhNX8PXep6o0WMWay1ng3MPt/tKKXitNaxjRBSiybfw0nyXRjkezA46vdgy6ahNCC02nyIdVmt6yilnAFvINuGMQkhhKjBlolgE9BTKdVVKeUK/BVYUmOdJcCN1ukpwGqttbZhTEIIIWqwWdOQtc3/HmAFYALmaK0TlVLPAHFa6yXAR8CnSql9QA5GsrCl825eaiXkezhJvguDfA8Gh/welJyACyGEY5Mni4UQwsFJIhBCCAfnMImgvnIXjkIplayU2q6U2qKUirN3PE1FKTVHKZWplNpRbZmfUmqlUmqv9a+vPWNsKnV8F7OUUmnW38UWpdQV9ozR1pRSoUqpNUqpJKVUolLqfutyh/xNOEQiaGC5C0cyUms9wMH6S38MjK2x7FHgZ611T+Bn67wj+JjTvwuA162/iwFa66VNHFNTqwD+prUOB4YCd1uPCQ75m3CIREDDyl2IVkxr/QtGz7Tqqpc4+QSY1KRB2Ukd34VD0Vof1VonWKePAzsxKh045G/CURJBbeUugu0Ui71p4CelVLy1dIcj66C1PmqdTgc62DOYZuAepdQ2a9ORQzSJAFirHkcDf+KgvwlHSQTipAu11gMxmsnuVkpdbO+AmgPrg4yO3Jf6XaA7MAA4Crxq33CahlKqLbAIeEBrXVD9PUf6TThKImhIuQuHoLVOs/7NBBZjNJs5qgylVEcA699MO8djN1rrDK21WWttAT7AAX4XSikXjCTwudb6G+tih/xNOEoiaEi5i1ZPKeWplGpXOQ1cBuw486dateolTm4EvrNjLHZVefCzuopW/ruwlrv/CNiptX6t2lsO+ZtwmCeLrd3h/svJchfP2zmkJqeU6oZxFQBGeZEvHOV7UEp9CYzAKDOcATwNfAssADoDh4BrtNat/iZqHd/FCIxmIQ0kA7dXaytvdZRSFwK/AtsBi3Xx4xj3CRzvN+EoiUAIIUTtHKVpSAghRB0kEQghhIOTRCCEEA5OEoEQQjg4SQRCCOHgJBEIh6aUMleruLmlMSvTKqXCqlf4bMD6nkqpVdbp36zjeAthc/JDE46uWGs9wN5BWA0DNljr/JzQWlfYOyDhGOSKQIhaWMdteMk6dsNGpVQP6/IwpdRqa3G2n5VSna3LOyilFiultlpfw62bMimlPrDWvP9JKeVey766K6W2AJ8B1wLxQJT1CiWwif7JwoFJIhCOzr1G09C0au/la60jgLcxnkoHeAv4RGsdCXwOvGld/iawTmsdBQwEEq3LewLvaK37AXnA1TUD0Frvt16VxGPU+PkEuNk6LoBD1LoR9iVPFguHppQq1Fq3rWV5MjBKa33AWpwsXWvtr5Q6BnTUWpdblx/VWrdXSmUBIVrr0mrbCANWWgc5QSn1D8BFa/1cHbFs0loPUkotAu7XWqc28j9XiFrJFYEQddN1TJ+N0mrTZmq5L6eUes96U7mntYloLPCDUurBc9ynEGdFEoEQdZtW7e8G6/R6jOq1ANdhFC4DY1jDO8EYGlUp5d3QnWit7wD+BTyLMSLWj9ZmodfPL3whGkZ6DQlH5249C6+0XGtd2YXUVym1DeOsfrp12b3AXKXUI0AWMNO6/H5gtlLqZowz/zsxBnhpqEuAecBFwLpz+pcIcY7kHoEQtbDeI4jVWh+zdyxC2Jo0DQkhhIOTKwIhhHBwckUghBAOThKBEEI4OEkEQgjh4CQRCCGEg5NEIIQQDu7/AULFPL7jaoc4AAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('/content/drive/MyDrive/Colab Notebooks/NLP_Project/attention_model')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vmTbw9G5F4qn",
        "outputId": "2b632636-af7d-4ef6-9414-55afa633dc9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as embedding_8_layer_call_fn, embedding_8_layer_call_and_return_conditional_losses, embedding_9_layer_call_fn, embedding_9_layer_call_and_return_conditional_losses, cross_attention_5_layer_call_fn while saving (showing 5 of 32). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title\n",
        "@Translator.add_method\n",
        "def translate(self,\n",
        "              texts, *,\n",
        "              max_length=50,\n",
        "              temperature=0.0):\n",
        "    # Process the input texts\n",
        "    context = self.encoder.convert_input(texts)\n",
        "    batch_size = tf.shape(texts)[0]\n",
        "\n",
        "    # Setup the loop inputs\n",
        "    tokens = []\n",
        "    attention_weights = []\n",
        "    next_token, done, state = self.decoder.get_initial_state(context)\n",
        "\n",
        "    for _ in range(max_length):\n",
        "        # Generate the next token\n",
        "        next_token, done, state = self.decoder.get_next_token(\n",
        "            context, next_token, done,  state, temperature)\n",
        "        \n",
        "        # Collect the generated tokens\n",
        "        tokens.append(next_token)\n",
        "        attention_weights.append(self.decoder.last_attention_weights)\n",
        "\n",
        "        if tf.executing_eagerly() and tf.reduce_all(done):\n",
        "            break\n",
        "\n",
        "    # Stack the lists of tokens and attention weights.\n",
        "    tokens = tf.concat(tokens, axis=-1)   # t*[(batch 1)] -> (batch, t)\n",
        "    self.last_attention_weights = tf.concat(attention_weights, axis=1)  # t*[(batch 1 s)] -> (batch, t s)\n",
        "\n",
        "    result = self.decoder.tokens_to_text(tokens)\n",
        "    return result"
      ],
      "metadata": {
        "id": "VZWcRAPDnhRs"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Testing"
      ],
      "metadata": {
        "id": "Nk1Af2GIIbOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def test_data():\n",
        "  test_source = []\n",
        "  test_target = []\n",
        "  with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/test.ur', \"r\", encoding=\"utf-8\") as f:\n",
        "      lines_urdu = f.read().split(\"\\n\")\n",
        "  with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bible/test.en', \"r\", encoding=\"utf-8\") as f:\n",
        "      lines_eng = f.read().split(\"\\n\")\n",
        "  for each in lines_eng:\n",
        "    test_source.append(each)\n",
        "  for each in lines_urdu:\n",
        "    test_target.append(each)\n",
        "  return test_source,test_target"
      ],
      "metadata": {
        "id": "ixInXc7opQ8e"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_source,test_target=test_data()"
      ],
      "metadata": {
        "id": "2uIKeGYIrDBz"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_source[45])\n",
        "print(test_target[45])\n",
        "print(len(test_source))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bqTSsk2rI2_",
        "outputId": "d22b6d19-4a46-44d1-a6c6-fc9b53c5f41d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And the nations were angry , and thy wrath is come , and the time of the dead , that they should be judged , and that thou shouldest give reward unto thy servants the prophets , and to the saints , and them that fear thy name , small and great ; and shouldest destroy them which destroy the earth .\n",
            "اور قوموں کو غصہ آیا اور تیرا غضب نازل ہؤا اور وہ وقت آ پہنچا ہے کہ مردوں کا انصاف کیا جائے اور تیرے بندوں نبیوں اور مقدسوں اور ان چھوٹے بڑوں کو جو تیرے نام سے ڈرتے ہیں اجر دیا جائے اور زمین کے تباہ کرنے والوں کو تباہ کیا جائے ۔\n",
            "258\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = [] \n",
        "total = 0\n",
        "for i in range(len(test_source)):\n",
        "    result.append(model.translate([test_source[i]])[0].numpy().decode())\n",
        "    total += nltk.translate.bleu_score.sentence_bleu([test_target[i]], result[-1], weights=[1])\n",
        "print(total/len(test_source))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8XR6TghzPIR",
        "outputId": "4f5e53b1-dccf-4d31-b9b0-ba0dc5f40d89"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6995529724014304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BLEU Score"
      ],
      "metadata": {
        "id": "qiNd_5ZHIgnF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_score=total/len(test_source)\n",
        "print(\"Bleu Score: \",bleu_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SZD2Vd8oFfuu",
        "outputId": "7b90149d-6ab5-4331-92e1-aa3d93a2f2b6"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bleu Score:  0.6995529724014304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/NLP_Project/Bleu_Score_With_Attention', 'wb') as file:\n",
        "  pickle.dump(bleu_score, file)"
      ],
      "metadata": {
        "id": "oE0BoINQFVfe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(test_source[200])\n",
        "print(test_target[200])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apxDYUvo-z_n",
        "outputId": "5678e377-b484-4e32-c50b-9464a0afbcf8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "And when the thousand years are expired , Satan shall be loosed out of his prison .\n",
            "اور جب ہزار برس پورے ہو چکیں گے تو شیطان قید سے چھوڑ دیا جائے گا ۔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = model.translate([\"and whosoever liveth and believeth in me shall never die . believest thou this ?\"]) # Are you still home\n",
        "result[0].numpy().decode()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Z-sb33bkovdt",
        "outputId": "ce521137-2cd2-4856-ecc8-6e5c18cdc273"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'اور جو کوئی مجھ پر ایمان لائے اور مجھ پر ایمان لاتا ہے وہ ابد تک کبھی کبھی نہ مریگا ۔ کیا تو یہ ہے ؟ ۔ '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 164
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5kCzruBQIKCj"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "uciYGwqLm5BF",
        "nxLtDAl6m-FM",
        "8wR-28EPnDrW",
        "A9dwHySSnm9n",
        "ABDv20f8qN9W",
        "QXYoLePCqZi2",
        "8dnI5DBcqiBu",
        "Wi5axMs8rH-i",
        "3ArvKwf7rN_m",
        "twGFWl0vrYr1",
        "FZ8AgHwyrlR-",
        "hS9cE8KXrp2L",
        "tmJ6JXmnrwEO",
        "DDWA1L9b3Vur",
        "dcuLlOOrcgoc"
      ],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}